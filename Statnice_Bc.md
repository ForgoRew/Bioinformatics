# README
Čauky!

Tenhle soubor jsou moje poznámky z průběžnýho učení na státnice. Neříkám, že jsou kompletní, ale někomu by se mohly hodit :)

Zatím jsou under construction :D

Vycházím ze [státnicových otázek na SISu](https://is.cuni.cz/studium/predmety/index.php?id=7b4a1f9cb7c5f97f6a546844bfc00ea4&tid=&do=predmet&kod=MSZBB004&skr=2022).

U některých zpracovaných otázek jsou odkazy na materiály, ze kterých vycházím (přednášky etc.).

==========

Teď uprostřed sepisování jsem si všiml, že některé poznámky jsou napsané dost mašťácky. Tak to berte pls jako spíš moje poznámky, kterými si připomínám teorii a pro cokoliv podrobnějšího se podívejte do zdrojů, které tam mám napsané. Sorry :D

# Otázky
## Požadavky znalostí k bakalářské státní závěrečné zkoušce z bioinformatiky

### Matematika & informatika
1. Matematická analýza
   1. Posloupnosti a řady, konvergence, Cauchyovské posloupnosti.
   2. Reálně funkce jedné proměnné. Limita v bodě a spojitost. Derivace funkcí: definice a základní pravidla, věty o střední hodnotě, derivace vyšších řádů. Extrémy funkcí. Aplikace, např. průběh funkcí, Taylorův polynom.
   3. Integrální počet. Primitivní funkce a Newtonův integrál. Určitý (Riemannův) integrál a jeho použití.
2. Lineární algebra
   1. Soustavy lineárních rovnic, metody řešení.
   2. Matice, operace s maticemi. Hodnost matice, regulární matice a inverzní matice. Odstupňovaný tvar matice.
   3. Základní algebraické struktury: grupy, tělesa, vektorové prostory.
   4. Základní vlastnosti konečně generovaných vektorových prostorů, vektorové podprostory. Báze a dimenze.
   5. Lineární zobrazení. Základní vlastnosti, maticová reprezentace, skládání lineárních zobrazení.
   6. Skalární součin a norma. Vlastnosti v reálném i komplexním případě, Cauchy-Schwarzova nerovnost. Kolmost. Ortogonální doplněk a jeho vlastnosti, ortogonální projekce.
   7. Determinanty. Definice a základní vlastnosti determinantu. Úpravy determinantů, výpočet.
   8.  Vlastní čísla a vlastní vektory matic. Výpočet a základní vlastnosti. Diagonální tvar matice, diagonalizovatelnost. Jordanův normální tvaru (v obecném případě).
3. Kombinatorika, pravděpodobnost a statistika
   1. Binární relace, ekvivalence a částečná uspořádání. Kombinatorické počítání: kombinační čísla, binomická věta, princip inkluze a exkluze.
   2. Teorie grafů. Základní pojmy teorie grafů: grafy a podgrafy, izomorfismus. Stromy a jejich základní vlastnosti, kostra grafu.
   3. Rovinné grafy, barvení grafů. Toky v sítícha aplikace. Souvislost grafů (míra souvislosti), Mengerovy věta.
   4. Náhodné jevy, podmíněná pravděpodobnost, nezávislost náhodných jevů. Náhodné veličiny, střední hodnota, linearita střední hodnoty. Bodové odhady a testování hypotéz.
4. Algoritmy a datové struktury
   1. Časová složitost algoritmů. Metoda ,,rozděl a panuj'' - aplikace a analýza složitosti, dynamické programování.
   2. Binární vyhledávací stromy, vyvažování, haldy.
   3. Třídění - sekvenční třídění, porovnávací algoritmy, přihrádkové třídění, třídící sítě.
   4. Grafové algoritmy - prohledávání do hloubky a do šířky, souvislost, topologické třídění, nejkratší cesta, kostra grafu, toky v sítích. Tranzitivní uzávěr.
   5. Algoritmy vyhledávání v textu - Aho-Corasicková, KMP, sufixový strom, sufixové pole. Algebraické algoritmy - DFT, Euklidův algoritmus. RSA. Aproximační algoritmy. Automaty a gramatiky - typy automatů a gramatik, vztahy, příklady.
5. Aplikovaná informatika
   1. Principy a základy implementace objektově orientovaných jazyků - třída, dědičnost, polymorfismus, virtuální funkce, atd. Generické programování a knihovny šablony a generika, kompilační polymorfismus.
   2. Normální formy, referenční integrita. Základy SQL.
   3. Unix - základní pojmy (systém souborů, komunikace mezi procesy), shell (syntaxe, programové konstrukty), základní utility.


### Biologie
1. Složení živých buněk - malé molekuly a makromolekuly, jejich interakce, vlastnosti vody a vodných roztoků důležité pro život, kyseliny, zásady a pufry, role vody v živých tělech,
2. Stavba buňky, funkce buněčných kompartmentů, srovnání buněčné stavby pro- a eukaryot, povrchové struktury buněk, význam specifických struktur rostlinných buněk (buněčné stěny, plastidů, vakuol) pro životní strategii rostlin
3. Membrány - stavba, biogeneze a funkce membrán, membránové proteiny, membránový potenciál a transmembránový přenos látek
4. Struktury proteinů a nukleových kyselin - primární, sekundární, terciální a kvartérní struktury, motivy a domény, supramolekulární komplexy (ribosom, spliceosom, proteasom...); princip komplementarity bází, primární a sekundární struktury DNA a RNA
5. Enzymy a jejich vlastnosti - mechanismy katalýzy, regulace enzymové aktivity, názvosloví enzymů
6. Energetický metabolismus - makroergní fosfátové sloučeniny, glykolýza a citrátový cyklus, fermentace, oxidativní fosforylace a transport elektronů, fotosyntéza - celkový přehled, dílčí reakce a komplexy, jejich lokalizace
7. Zpracování genetické informace. Centrální dogma molekulární biologie, struktura virových, pro- a eukaryotických genomů. Vertikální a horizontální přenos dědičné informace. Transpozony, viry, epigenetická dědičnost, priony
8. Základy genetiky - Mendelovy zákony, základní pojmy, různé verze definice genu. Intra- a intergenové interakce, genová vazba, genetické aspekty sexuality, chromozomové určení pohlaví, pohlavně vázaná dědičnost, mimojaderná dědičnost.
9. Mutace a mutageneze - mutace genové, chromozomové a genomové, molekulární podstata mutací, mutageny, reparace poškozené DNA
10. Exprese genů a její regulace na úrovni transkripční, posttranskripční, translační a posttranslační, genetický kód, syntéza a distribuce proteinů v buňce, folding a účast chaperonů, posttranslační modifikace, regulace stability proteinů
11. Dynamika a funkce buněčných kompartmentů - endoplasmatické retikulum, Golgiho komplex, vezikulární transport, endo- a exocytóza, sekreční dráha a nitrobuněčné adresování proteinů, lyzosom, vakuoly, peroxisom, hydrogenosom
12. Funkční anatomie buněčného jádra - stavba jádra, jaderný obal, organizace genetické informace, chromozomy, chromatin, jadérko
13. Semiautonomní organely - evoluční historie, stavba, funkce, replikace a exprese organelového genomu
14. Cytoskelet - cytoskeletální proteiny, molekulární motory a jiné asociované proteiny, interakce s dalšími buněčnými strukturami, úloha v morfogenezi buňky a buněčném cyklu, růst a pohyb buněk
15. Mezibuněčné spoje a mezibuněčná hmota –napojení buněk na mezibuněčnou hmotu, složení a význam mezibuněčné hmoty; buněčná stěna u prokaryot a eukaryot
16. Buněčný cyklus a programovaná buněčná smrt - porovnání cyklu prokaryotní a eukaryotní buňky, fáze cyklu, replikace DNA, u eukaryot jaderné dělení, mitoza a meioza, rekombinace DNA, cytokineze, apoptóza, buněčná onkogeneze
17. Komunikace uvnitř buněk a mezi buňkami, mezibuněčný a intracelulární přenos signálu, membránové a intracelulární receptory, vybrané příklady signálních drah
18. Principy základních metod molekulární biologie - metody analytické separace makromolekul, PCR, sekvenování, molekulární klonování, genomika, proteomika, transkriptomika. Modelové organismy v molekulární biologii a genetice a jejich krátký popis a srovnání. Nejvýznamnější sekvenační projekty 
19. Evoluce, různá její pojetí, významné události v dějinách teorie evoluce.
20. Lamarckismus, darwinismus, neodarwinismus
21. Mechanismy evoluce - drift, draft, evoluční tahy, genový tok, selekce
22. Mutace jako zdroj evolučních novinek, typy mutací, náhodnost mutací co do místa, času a směru
23. Selekce - mechanismus, typy, úrovně
24. Pohlavní výběr - intrasexuální a intersexuální selekce, epigamní znaky, evoluce
25. Speciace: mechanismy a typy speciací
26. Evoluce pohlavního rozmnožování
27. Homologie, analogie, plesiomorfie a apomorfie v evoluci organismů


### Bioinformatika
1. definice oboru- historie bioinformatiky – oblasti bioinformatiky- biologická data
2. sekvenční srovnávání - dotplot – substituční tabulky – metody dynamického programování–lokální a globální alignment – parwise versus multiple sequence alignment
3. hledání podobných sekvencí – Blast versus FASTA - statistické zhodnocení významnosti nálezu - profilové metody (PSI-BLAST) – HMM metody
4. hledání domén a motivů – predikce transmembránových proteinů – predikce buněčné lokalizace a postranslačních modifikací
5. databáze – vlastnosti databází – formáty dat- validace dat – významné bioinformatické databáze
6. strukturní srovnávání – hledání podobných struktur
7. predikce struktury makromolekul
8. fylogenetika – stavba stromů – základní metody tvorby stromů (ML, MP, NJ, Bayes) – bootstrap analýza

## Výpočet času
|Okruh                           |n otázek|koef. učení|tok/h|hodin|reálně|reál. koef.|
|:-------------------------------|:------:|:---------:|:---:|:---:|:----:|:---------:|
|Matematika & informatika        |23      |1.25       |2    |57   |||
|Biologie - molekulární a buněčná|27      |1.00       |2    |54   |||
|Bioinformatika                  |8       |0.9        |2    |14.4 |19|1.1875|
|Celkem                          |58      |-          |2    |125.4|||


# Poznámky
## Co jsem ještě nestihl doprojít
<!-- TODO -->
- Hidden Markov Models
  - [Bioinformatické algoritmy, přednášky 7,8,9](https://drive.google.com/drive/u/2/folders/1jAY334cmBiOS3Tx06VBPDkjNM--tGqBo)

- derivace
  - základní vzorečky pro derivování
## Co bych si rád ještě připoměl
- derivace
  - vzoreček pro definici derivace
  - leibnitzova formule
  - Taylorův polynom
  - zkusit si pár příkladů
- integrály
  - definice primitivní funkce
  - vzorečky pro výpočet délky křivky funkce a objem tělesa
- nerovnosti
  - Markovova
    - na wiki se jmenuje "Čebyševova nerovnost I. typu"
    - pro náhodnou veličinu X a $\epsilon>0$ platí
      - $P(X>\epsilon) \leq \frac{E(X)}{\epsilon}$
  - Čebyševova
    - na wiki "Čebyševova nerovnost II. typu"
    - pro náhodnou veličinu X a $\epsilon>0$
      - $P(|X-E(X)<\epsilon) \geq \frac{var(X)}{\epsilon^2}$
  - Cauchy-Schwarzova
    - lingebra
      - absolutní hodnota skalárního součinu dvou vektorů je nejvýše hodnota součinu norem těchto vektorů



## Matematika & informatika
### 1. Matematická analýza
- k celé matematické analýze jsou [sripta od Klimošové ("poznámky z přednášek") na disku](https://drive.google.com/drive/u/2/folders/1iJyceZk9aKkYBAnl3T4XAQ2f2PTM7tpD)
- dále [řešená cvičení](https://drive.google.com/drive/u/2/folders/1w_V7L8AeSFNtrY82J33ATe0AU3vG7-6z)
  - a tamtéž je i fajn tahák ze studnice vědomostí (vzorečky na hodnoty goniometrických funkcí, derivace, integrování etc.)

- podle spolužáků, co už mají státnice za sebou:
  - u státnic jsou otázky i v matematice prý spíš povídací
  - u důkazů jsou potřeba vědět hlavně jejich myšlenky
  - jsou potřeba základní definice
  - počítací věci jen hodně v základu, určitě žádné "špeky"
#### 1. Posloupnosti a řady
> Posloupnosti a řady, konvergence, Cauchyovské posloupnosti

- literatura
  - přednášky 2, 3 ve skriptech
  - kromě Cauchyovské posloupnosti - [dávám odkaz na Wikipedii](https://cs.wikipedia.org/wiki/Cauchyovsk%C3%A1_posloupnost)

- nejprve definice posloupnosti:
  - Nechť *M* je množina. Pak posloupnost s hodnotami v M je zobrazení z ***ℕ*** do *M*.
    - Každé přirozené číslo je tedy zobrazené na nějaký prvek z *M*
    - $(a_1,a_2,a_3,...)$ se značí jako $(a_n)_{n=1}^{∞}$
- posloupnost může být:
  1. omezená (shora/zdola)
  2. rostoucí/klesající
  3. monotónní <=> nerostoucí nebo neklesající

- posloupnost může mít limitu
  - vlastní limita je definovaná v reálných číslech
  - definice pro limitu v nekonečnu (nevlastní limita) je podobná
  - Řekneme, že posloupnost $(a_n)_{n=1}^{∞}$ má limitu v bodě L, pokud
    - L ∈ ℝ
    - pro každé $ϵ$ ∈ ℝ existuje $n_0$ ∈ ℕ
      - pro každé $n$ > $n_0$, $n$ ∈ ℕ
      - $a_n$ - L < $ϵ$

  - věta o jednoznačnosti limity
    - každá posloupnost má nejvýše jednu limitu
    - => když najdeme dvě podposloupnosti s různými limitami, posloupnost nemá limitu
  - věta o aritmetice limit
    - pro dvě posloupnosti s limitami
    - součet posloupností má limitu danou součtem limit původních posloupností
    - to stejné platí o součinu i o podílu, jen je potřeba si zkontrolovat, že je výraz definovaný (žádné dělení nulou nebo součiny nekonečna s mínus nekonečnem)
  - věta o limitě a uspořádání
    - pro dvě posloupnosti s limitami v bodech a,b ∈ ℝ
    - pokud a>b, tak pro nějaké $n_0$ budou i další hodnoty první posloupnosti větší než druhé
  - věta o dvou policajtech
    - pokud si můžeme "uzavřít" posloupnost do dvou posloupností - jedna bude vždycky větší a druhá vždycky menší - a ty mají limitu v jednom čísle, tak i ta uzavřená posloupnost v něm má limitu
  -  věta monotónní posloupnosti
    -  každá monotónní posloupnost má monotónní podposloupnost

- řada je vlastně suma členů posloupnosti
  - nekonečná řada je suma všech prvků posloupnosti
  - n-tý částečný součet řady je součet pouze prvních n prvků posloupnosti

  - důležité příklady řad
    - geometrická řada
      - $\sum_{n=0}^∞q^n$
        - q ∈ (-1,1) ... součet řady je $\frac{1}{1-q}$
        - q ∈ [1,∞) ... dtto je ∞
        - q ∈ [-1,-∞) ... dtto neexistuje
    - řady typu
      - $\sum_{n=0}^∞\frac{1}{n^s}$
        - konvergují, pokud s>1
        - jinak divergují
        - pokud s = 1 -> **harmonická řada**
          - diverguje, ale její prvky konvergují k 0

- Cauchyovské posloupnosti
  - používá se pro definici metrického prostoru
  - je to posloupnost, jejíž členové mohou být libovolně blízko sebe
    - tzn. pro libovolné reálné číslo budou existovat 2 prvky této posloupnosti, které budou mít k sobě menší vzdálenost
    - každá konvergující posloupnost je zároveň Cauchyovská
      - opačně implikace neplatí
        - např. pokud operujeme v racionálních číslech, tak Cauchyovská posloupnost může konvergovat k iracionálnímu číslu
    - metrický prostor úplný pouze tehdy, když má každá Cauchyovská posloupnost v tomto prostoru i svou limitu

#### 2. Reálné funkce a limity
> Reálně funkce jedné proměnné. Limita v bodě a spojitost. Derivace funkcí: definice a základní pravidla, věty o střední hodnotě, derivace vyšších řádů. Extrémy funkcí. Aplikace, např. průběh funkcí, Taylorův polynom.

- literatura
  - kapitola 4

- Reálné funkce jedné proměnné
  - funkce, které řešíme, jsou definované z M do R, M je podmnožina R
  - funkce může být
    - shora/zdola omezená - pro funkci existuje horní/dolní závora
    - rostoucí/klesající
    - monotónní/nerostoucí/neklesající
    - periodická - existuje *p*, které když přičteme k jakémukoli *x*, tak dostaneme zase stejnou hodnotu funkce
    - prostá - různé hodnoty v definičním oboru implikují různé hodnoty v oboru hodnot
  - inverzní funkce k $f$
    - $f^{<-1>}(y)=x$ <=> $f(x)=y$
  - elementární funkce
    - Eulerovo číslo ... definováno jako součet řady
      - $e(x):=\sum_{n=0}^∞\frac{x^n}{n!}$
      - $e:=e(1)≈2.7$
    - logaritmus - řešení rovnice $e^x=y$
    - goniometrické funkce
      - sinus, cosinus, tangens, cotangens
    - cyklometrické funkce
      - arcsin, arccos, arctan
        - inverzní funkce na intervalu (-1,1)

- Limita v bodě a spojitost.
  - je potřeba definovat okolí bodu
    - $δ$-okolí bodu $a$ - $U(a,δ)$
      - $δ ∈ ℝ$, $δ > 0$
      - $a ∈ ℝ$
      - $U(a,δ) := {x ∈ ℝ: |a-x|<δ}$
        - pro a ∈ {-∞, ∞}
          - pro ∞, podobně pro -∞: $U(a,δ) := {x ∈ ℝ: x>1/δ}$
    - prstencové okolí bodu je definované jako okolí bodu bez toho bodu
  - definice limity
    - limita pro funkci $f$ má v bodě $a$ hodnotu $A$, pokud pro všechna $ϵ$ existuje $δ$ takové, že se prstencové okolí bodu $a$ zobrazí na okolí bodu $A$
      - $x∈P(a,ϵ) => f(x)∈U(A,δ)$
    - zajímavé je, že funkce ani nemusí být definovaná v bodě a, aby tam mohla mít limitu
    - ještě je zajímavé, že když sčítáme, násobíme a dělíme funkce navzájem, tak se stejně dá operovat s jejich limitami (musí být ale definované a i ty operace musí být definované)
  - spojitost funkce
    - funkce $f$ je spojitá v bodě $a ∈ ℝ$, pokud hodnota její limity je rovna hodnotě funkce $f$ v tomto bodě
    - např. absolutní hodnota signum ($|sgn|$) není spojitá v nule - limita je v bodě 0 rovna 1, ale funkce má v bodě 0 hodnotu také 0
  - na spojitých funkcích je např. zajímavé, že zobrazuje interval vždy na nepřerušený interval

- Derivace funkcí: definice a základní pravidla
  - derivace z fyzikálního pohledu říká něco jako "rychlost" růstu určité funkce
    - toho se využívá při aproximacích funkcí, např. pomocí Taylorova polynomu
  - definice derivace:
    - máme funkci $f:M→ℝ$,
    - bod $b∈M$,
    - okolí bodu $U(b,δ)$, $δ>0$
    - pak derivace funkce $f$ v bodě $b$ je definovaná takto:
      - $f':=lim_{h→0}\frac{f(b+h)-f(b)}{h}=lim_{x→b}\frac{f(x)-f(b)}{x-b}$
  - vlastnosti derivace
    - derivace existuje, pokud existují příslušné jednostranné derivace
    - zajímavost (viz úvod) - druhá definice derivace je v podstatě směrnice přímky dané bodem [x,f(x)] a [b,f(b)]
  - věta: diferencovatelnost implikuje spojitost funkce
    - pokud existuje v bodě $b$ derivace, pak je funkce v bodě $b$ spojitá
  - věta: aritmetika derivací
    - trochu složitější oproti limitám!
    - sčítání funkcí funguje v pohodě
    - násobení funkce reálným číslem je taky v pohodě
    - pro násobení je Leibnitzova formule:
      - $f, g: U(b,δ)→ℝ$ jsou funkce, které mají v bodě b derivace
      - $(f⋅g)'(b) = f'(b)g(b) + f(b)g'(b)$
    - pro dělení je formule docela podobná násobení
      - $(\frac{f}{g})(b)' = \frac{f'(b)g(b) - f(b)g'(b)}{g(b)^2}$
  - věta: derivace složené funkce
    - funkce $f,g$,
    - body $a,b$,
    - $f$ má derivaci v bodě $b$
    - $g$ má derivaci v bodě $a$
    - $g(a) = b$
    - $g$ je spojitá v bodě $a$
    - pak platí, že
      - $(f(g))'(a) = f'(b)g'(a)$
  - věta: derivace inverzní funkce
    - $f→J$ je na $J$ spojitá a ryze monotónní funkce a $f(a)=b$
    - pak když $b!=0$: $(f^{<-1>})'(b) = 1/f'(a)$
    - jinak když je $f$ rostoucí, tak $(f^{<-1>})'(b) = ∞$
      - (když je klesající, tak -∞)
  - věta: L'Hospitalovo pravidlo
    - funkce $f,g$ mají na $P(a,δ)$ vlastní derivaci a $g'(a)!=0$ na $P(a,δ)$
    - pak i pokud jejich limity na $P(a,δ)$ jsou rovny nule, platí, že
      - $lim_{x→a}\frac{f(x)}{g(x)}=lim_{x→a}\frac{f'(x)}{g'(x)}$
    - pokud má funkce $g$ limitu rovnou $+-∞$, pak platí výše uvedená rovnice také.
    - to platí i pro jednostranné limity
  - věta: nutná podmínka pro lokální extrém
    - pokud funkce v bodě $a$ nemá nulovou derivaci, pak se v bodě $a$ nenachází (lokální) extrém funkce

      - 

- věty o střední hodnotě
  - věta: Rolleova a Lagrangeova (o střední hodnotě)
    - Rolleova věta
      - pomocí ní jde ověřit, že na nějakém intervalu je minimum
      - nechť $-∞ < a <b < ∞$
      - funkce $f$
        - je na intervalu $[a,b]$ spojitá
        - má na intervalu $(a,b)$ derivaci
        - $f(a)=f(b)$
      - Pak existuje $c∈(a,b)$ takové, že $f'(c)=0$.
    - Lagrangeova věta je zobecnění Rolleovy věty.
      - f(a) se nemusí rovnat f(b)
      - existuje c takové, že $f'(c)=\frac{f(b)-f(a)}{b-a}$
    - ze vzorečku Lagrangeovy věty se dá vyjít pro definování konvexity a konkavity funkce
      - Pro interval $I$ a funkci $f: I→ℝ$
        - $f$ je konvexní na $I$, pokud pro všechna $a,x,b ∈ I$,
          - $a<x<b$
        - platí, že $f(x)≤f(a)+(x-a)\frac{f(b)-f(a)}{b-a}$
          - tzn oproti jakékoli přímce vytvořené na fuknkci dvěma body je funkce vydutá
        - pro konkávní je to stejné, jen naopak - je vypouklá
          - $f(x)≥f(a)+(x-a)\frac{f(b)-f(a)}{b-a}$
        - ryze konvexní a ryze konkávní je funkce, když platí rovnice bez rovnosti - funkce |x| je konkávní, ale ne ryze

- derivace vyšších řádů
  - věta: konvexita, konkavita a druhá derivace
    - mějme funkci f na intervalu I
      - pokud je druhá derivace f'' na I kladná, pak je f na I konvexní
      - pokud je druhá derivace f'' na I záporní, pak je f na I konkávní

- Extrémy funkcí.
  - v poznámkách jsem to trochu přejel, ale myslím, že se to řeší přes derivaci funce - kde je derivace 0 tam může být lokální extrém, viz teorii okolo Rolleovy věty

- Aplikace, např. průběh funkcí,
  
- Taylorův polynom.
  - pomocí něj se dají aproximovat různé funkce
  - pro motivaci - aproximace funkce $f$ v bodě např. $a$
    - bude funkce $t(x) = f(a)+f'(a)(x-a) $
      - tedy přímka procházející bodem $a$ se směrnicí $f'(a)$
    - $t$ je v tomto případě polynom stupně 1, pro který platí
      - $\lim_{x→a}\frac{f(x)-t(x)}{x-a}=0$
  - nyní hledáme polynom P stupně nejvýše n, pro který platí
    - $\lim_{x→a}\frac{f(x)-P(x)}{(x-a)^n}=0$ (existuje právě jeden)
  - definice Tailorova polynomu
    - $a ∈ ℝ$
    - $f$ je definovaná v okolí $a$ a má zde derivaci $n$-tého stupně ($f^{n}(a) ∈ ℝ$)
    - pokud $n = 0$, předpokládáme spojitost $f$ v bodě $a$
    - pak Taylorův polynom řádu $n$ funkce $f$ v bodě $a$ je definován jako suma:
      - $T^{f,a}_n:=∑_{i=0}^n\frac{f^i(a)}{i!}(x-a)^i$

#### 3. Integrály
> Integrální počet. Primitivní funkce a Newtonův integrál. Určitý (Riemannův) integrál a jeho použití.

- Literatura
  - skripta, kapitoly 10-13

- primitivní funkce
  - funkce, která umožňuje z derivované funkce rekonstruovat původní funkci
  - definice primitivní funkce
    - nechť $-∞ < a < b < ∞$
    - nechť je definovaná funkce $f: (a,b) → ℝ$
    - nechť je definovaná funkce $F: (a,b) → ℝ$, která má na $(a,b)$ derivaci $F'$
    - pokud $F'(x) = f(x)$ pro všechna $x ∈ (a,b)$, nazveme funkci $F$ primitivní funkcí k funkci $f$
  - výše uvedená definice nám ještě moc neříká o tom, jak integrovat, jen, že je to opačný proces k derivování
  - navíc je určena až na konstantu
    - tzn., pokud je $F_1$ primitivní funkce $f$, pak $F_2 = F_1 + c$, $c ∈ ℝ$, je také primitivní funkce k $f$
    - $∫$ je symbol, který označuje množinu všech primitivních funkcí
    - $F(x) ∈ ∫f(x)dx$
  - věta: spojitá funkce má primitivní funkci
  - věta: funkce s primitivní funkcí má Darbouxovu vlastnost
    - (interval se zobrazí na interval)
  - věta: aritmetika primitivních funkcí
    - pozor, na rozdíl od derivací není obecný vzoreček pro násobení a dělení!
    - mějme funkce $f,g$,
    - které mají na intervalu I ∈ ℝ
    - primitivní funkce $F,G$
    - mějme skaláry $α, β ∈ ℝ$
    - pak platí, že
      - $(αF + βG)' = αf+βg$
    - tzn. funguje sčítání, odčítání a násobení skalárem
  - neexistuje univerzální technika pro výpočet primitivní funkce (ve skriptech uvádí [Klimošová tohle přirovnání](https://xkcd.com/2117/)):
  - ![differentiation_and_integration](differentiation_and_integration.png)

- počítání primitivních funkcí
  - věta o substituci
    - je to věta o derivaci složené funkce naruby
    - $∫ f(ϕ'(t))ϕ'(t) dt = F(ϕ(t))+c$
  - věta: integrace per partes
    - pro funkce $f,g$,
    - které jsou spojité na intervalu $I ∈ ℝ$
    - a mají na $I$ primitivní funkce $F,G$
    - platí, že
      - $∫f(x)G(x)dx + ∫F(t)g(t)dt = F(x)G(x) + c$
    - ((vzoreček je Leibnitzova formule naruby))
  - aplikace věty o integraci per partes
    - předchozí věta dává přímočaře vzoreček na úpravu integrálu, který se občas může hodit
      - $∫f(x)G(x)dx = F(x)G(x) - ∫F(t)g(t)dt$
  - řešení racionálních funkcí
    - obecně jsou integrály pro racionální funkce (funkce, která je možná napsat jako podíl dvou polynomů)
    - řešitelné
      - výsledná funkce se bude skládat z racionálních funkcí, logaritmu a arctangens
    - to sice nedává ještě návod k jejich řešení, ale tak co už

- určitý integrál
  - přímo k primitivním funkcím se vztahuje Newtonův integrál
  - definice Newtonova integrálu
    - hodí se, když na intervalu známe hodnotu primitivní funkce pro funkci
    - mějme funkci $f: (a,b)→ℝ$,
    - $a, b ∈ ℝ$
    - předpokládáme, že $F$ je primitivní funkce $f$ na intervalu $(a,b)$ s limitami v bodech $a,b$
    - pak Newtonův integrál je toto:
    - $[F]_a^b=∫_a^bf(x)dx = F(b^-)-F(a^+)=\lim_{x→b^-}F(x)-\lim_{x→a^+}F(x)$
      - tady vidím analogii pro počítání pravděpodobnosti jevu ve spojitém rozdělení pomocí CDF v určitém intervalu
  - pro Newtonův integrál fungují metody zmíněné u výpočtu primitivní funkce
    - věta: per partes
    - věta: substituce
  - druhý typ integrálu (Riemannův integrál) vychází z trochu víc geometrické motivace
    - jde o to spočítat plochu pod grafem funkce $f$
  - definice Riemannova integrálu
    - definice je trochu složitější,
    - je potřeba si definovat dělení intervalu a horní a dolní sumu
    - horní a dolní Riemannův integrál
      - pak když se tyto rovnají, máme teprve Riemannův integrál
    - začneme tím, že máme body $a,b ∈ ℝ$ (tedy bez nekonečen)
    - "dělení" $D$ je $k$-tice bodů $(a_0,a_1,...,a_k)$, splňující, že
      - $a = a_0 < a_1 < ... < a_k = b$
      - dělení $D$ dělí interval $I=[a,b]$ na intervaly
        - $I_i = [a_i,a_{i+1}]$ s délkou $|I_i|$
    - nyní můžeme definovat horní (S) a dolní (s) sumu
      - pro dělení $D$ má horní suma hodnotu součtu nejvyšších hodnot funkce $f$ na intervalech $I_i$
        - formálněji
          - $m_i=inf{f(x):x∈I_i}$
          - $M_i=sup{f(x):x∈I_i}$
        - $s(f,D) = ∑_{i=0}^{k-1}m_i×|I_i|$
        - $S(f,D) = ∑_{i=0}^{k-1}M_i×|I_i|$
      - pardoon, nechce se mi dopisovat horní a dolní integrál, ale jde o to, že jsou definované jako nejvyšší resp. nejnižší suma přes všechna dělení
      - pokud se rovnají, mají hodnotu Riemannova integrálu
- vlastnosti určitých integrálů
  - tvrzení: když není funkce omezená, Riemannův integrál neexistuje
  - věta: vlastnosti dělení a horního/dolního Riemannova integrálu
    - jako to je docela obvious, ale pro všechna dělení je dolní suma ≤ dolní integrál ≤ horní integrál ≤ horní suma
  - příklad na počítání
    - pro výpočet Riemannova integrálu funkce 1/x na intervalu [0,1] se použilo vlastně převodu hledání nejmenší a největší sumy na limitu posloupnosti
      - $∫_0^1xdx$
      - dělení $D_n = (0, 1/n, 2/n, ... 1)$
        - sumy
          - $s(f,D_n)=∑_{i=1}^n 1/n \frac{i-1}{n}$
          - $S(f,D_n)=∑_{i=1}^n 1/n \frac{i}{n}$
        - $lim_{n→∞}(∑_{i=1}^n 1/n\frac{i-1}{n}) = lim_{n→∞}(∑_{i=1}^n 1/n\frac{i}{n})=1/2$
  - věta: kritérium integrovatelnosti
    - funkce je Riemannovsky integrovatelná právě tehdy, když pro všechna $ϵ>0$ existuje dělení $D$ takové, že $0≤ S(f,D)-s(f,D) < ϵ$
  - věta: pokud je funkce monotónní, pak je Riemannovsky integrovatelná
  - věta: pokud je funkce spojitá, pak je také Riemannovsky integrovatelná
  - věta: 1. základní věta analýzy
    - pokud je funkce $f$ na intervalu $[a,b] ∈ ℝ$ Riemannovsky integrovatelná a uděláme funkci "F", která je definována jako Riemannův integrál $f$ od bodu $a$ do bodu $x∈[a,b]$, pak "F" je spojitá a její derivace je rovna funkci $f$
    - tedy věta přiznává Riemannovskému integrálu některé vlastnosti primitivní funkce
  - věta: 2. základní věta analýzy
    - pokud existuje Newtonův a Riemannův integrál funkce, pak jsou si rovny
  - věta: spojité funkce jsou Newtonovsky i Riemannovsky integrovatelné
    - pozor, existují funkce s Newtonovým, ale ne Riemannovým integrálem a naopak
  - věta: integrální kritérium konvergence
    - dává do souvislosti konvergenci řad a limitu integrálu
- aplikace
  - integrály jsou fajn na počítání ploch a délek křivek
    - pro složitější případy je potřeba vícerozměrný integrál
  - věta: délka křivky funkce
    - nechť funkce $f: [a,b] → ℝ$ má na $[a,b]$ spojitou derivaci $f'$
      - pak na délku křivky funkce $f$ platí vzoreček
        - $∫_a^b\sqrt{1+(f'(t))^2}dt$ 
  - věta: objem a povrch rotačního tělesa
    - těleso O, vzniklé rotací rovinného útvaru daného funkcí $f: [a,b] → ℝ$ a body $a,b ∈ ℝ$ okolo osy $x$
      - objem ... $π∫_a^bf(t)^2dt$
      - povech ... $2π∫_a^bf(t)\sqrt{1+(f'(t))^2}dt$


### 2. Lineární algebra
- mám záměr dělat celou lingebru z Hladíkovy učebnice - Lineární algebra nejen pro informatiky
  - je na [Google Disku Bioinformatika](https://drive.google.com/drive/folders/0BzEbjnxrwP6Obi1BT0dzX25zelE?resourcekey=0-FmLJvLRy3SlujojoDsMReA&usp=sharing)
#### 1. Soustavy lineárních rovnic, metody řešení.
> Soustavy lineárních rovnic, metody řešení.
- tahle otázka se většinou řeší na začátku skript, jako dobrá motivace pro zavedení matic
- důležité pojmy jsou kromě matice tzv. elementární operace, tedy operace s maticí, které nezmění množinu řešení lieárních rovnic, které matice reprezentuje
- dále Gaussova(-Jordanova) eliminace, což jsou postupy, jak z maticové reprezentace lineárních rovnic získat jejich řešení
- z dalších kapitol víme, že soustava má právě jedno řešení, pokud je matice regulární - v opačném případě má soustava 0 nebo nekonečně mnoho řešení a matice je singulární

- strašně moc se mi nechce se vypisovat s definicí matice a vektoru, doufám, že to je jasný (prostě tabulka/jednorozměrná tabulka čísel)
- soustava lineárních rovnic je *n* rovnic, Ax=b, kde x je vektor neznámých, b je to za rovnítkem u rovnic a A je to před rovnítkem. Soustava má řešení, pokud existuje právě jeden vektor x, který rovnici vyhovuje
- elementární operace jsou ty, které nezmění množinu řešení soustavy rovnic
  1. vynásobení řádku (reálné nenulové číslo)
  2. přičtení násobku jednoho řádku k druhému
  3. prohození řádků
- Gaussova eliminace
  1. dopředná eliminace - pomocí elementárních úprav je matice převedená do odstupňovaného stavu
  2. substituce - postupně se dosazují hodnoty neznámých do rovnic a určují se zatím neurčené
- odstupňovaný tvar matice (REF(A), row echelon form) 
  - pro matici $n×m$
    - řádky 1...r jsou nenulové
    - řádky r+1 ... m jsou nulové
    - každý nenulový řádek má jednoho pivota
      - tady to je potřeba napsat matematicky, hrozně se mi do toho nechce
        - $p_i=min(j: a_{ij}!= 0)$, $p_1<p_2<p_3<...<p_r$
      - sloupce p1,...pr se nazývají bázické, ostatní nebázické - to pak souvisí s vektorovými prostory...
- hodnost matice ($rank(A)$) je počet nenulových řádků (tedy číslo *r*)
- redukovaný REF (RREF(A), reduced row echelon form)
  - jako REF, ale na místech pivotů jsou jen jedničky a jinak nuly, vlastně to odstraňuje nutnost provést krok substituce - máme přímo hodnoty jednotlivých neznámých
- Frobeniova věta
  - soustavy jsou řešitelné právě tehdy, když hodnost matice A je stejný jako hodnost rozšířené matice A|b (b je vektor hodnot za rovnítkem u rovnic)


- soustavy lineárních rovnic, metody řešení.


#### 2. Matice, operace s maticemi
> Matice, operace s maticemi. Hodnost matice, regulární matice a inverzní matice. Odstupňovaný tvar matice.

- matice je tabulka čísel, pro reálná čísla, n řádků a m sloupců se tato matice značí $ℝ^{n×m}$
- vektor je speciální případ matice s pouze 1 sloupcem

- hodnost matice je počet pivotů po převedení matice do REF tvaru
- regulární matice je speciální typ matice
  - pojem má smysl jen pro čtvercovou matici (m=n)
  - matice A je regulární, pokud soustava $Ax=0^n$ má pouze jedno řešení - $x=0^n$
  - jinak se matice nazývá *singulární*
- regulárita matice $A ∈ ℝ^{n×n}$ je ekvivalentní s tím, že
  - matice $RREF(A) = I_n$ ($I_n$ je jednotková matice - má jedničky na diagonále)
  - $rank(A)=n$
- tohle má vztah i k řešení soustavy lineárních rovnic
  - A je regulární je ekvivalentní s tím, že soustava rovnic Ax=b má řešení pro libovolné b
- co se týká maticového násobení, pokud A,B jsou regulární matice, pak jejich součin je regulární
- pokud alespoň jedna z nich je singulární, pak i jejich násobek je singulární
- elementární úpravy - jde snadno ukázat, že celý proces Gaussovy(-Jordanovy) eliminace jde vyjádřit jako násobení matice A regulární maticí elementárních úprav Q
- mch., každá regulární matice jde vytvořit postupnými elementárními operacemi jednotkové matice
- a to se teď využije u inverzní matice
  - $RREF(A) = AQ = I_n$
  - $I_nQ^{-1}=A$
  - Q je inverzní matice k A (A^{-1}=Q)

- regularita matice je ekvivalentní s tím, že matice má inverzní matici
- jinak inverzní matice je definována tak, že $A^{-1}$ je inverzní k matici A, pokud $A^{-1}A = AA^{-1} = I_n$

- transponovaná matice - $A^T$ - matice s prohozenými indexy řádků a sloupců

- odstupňovaný tvar matice je popsaný v předchozí otázce


#### 3. Základní algebraické struktury: grupy, tělesa, vektorové prostory.
> Základní algebraické struktury: grupy, tělesa, vektorové prostory.

- úvod
  - tohle téma je pokryté ve dvou přednáškách
  - grupy a tělesa jsou potřeba pro použití 

- grupa
  - mega abstraktní pojem
  - množina s binární operací
    - aby množina s tou nějakou operací byla grupa, musí splňovat 3 podmínky
      1. operace je asociativní (je jedno, v jakém pořadí jsou na prvcích operace provedeny, např. (1 + 2) + 3 = 1 + (2 + 3))
      2. existuje neutrální prvek, (tzn. v množině je prvek, který přes operaci nezmění výsledek (0+1 = 1, 0 je neutrální prvek))
      3. ke každému prvku existuje inverzní prvek (tzn. při operaci prvku a inverzního prvku je výsledkem neutrální prvek, např. 1 + (-1) = 0)
  - speciální typ grupy je Abelova grupa, která splňuje komutativitu (je jedno, jestli sčítám 1+2 nebo 2+1)
  - konkrétní příklady grup jsou ve skriptech na str. 63-64
  - prvky v grupě mají několik vlastností (Tvrzení 4.4)
    - docela u toho funguje intuice ze sčítání na celých číslech a násobení na $R\{0}$...
  - grupa může mít tzv. podgrupu, což je grupa, jejíž množina prvků je podmnožinou té původní grupy a její operace dává na jejích prvcích stejný výsledek, jako originální operace
- ve skriptech jsou teď permutace, ale to bych přeskočil
- důležité, že permutační grupy jsou zajímavá skupina grup...

- těleso
  - potřebujeme množinu a dvě operace, které vytvoří Abelovy grupy
  - Těleso je množina $T$ s dvěma operacemi ("+" a "×")
    - (T,+) je Abelova grupa, nulový prvek "0" a inverzní prvek k prvku a je -a
    - (T\\{0},×) je také Abelova grupa, nulový prvek je "1" a inverzní prvek prvku a je a$^{-1}$
    - také musí platit distributivita
      - a × (b + c) = a × b + a × c
  - charakteristika tělesa ... kolik "1" musíme "sečíst" ("+"), abychom získali "0"
    - $Z_n$ má charakteristiku $n$
    - pokud $n$ neexistuje (nekonečná tělesa, např. $R$), je charakteristika 0
  - věta: Malá Fermatova
    - prvočíslo p,
    - těleso $Z_p$
    - $0 \neq a ∈ Z_p$
      - platí, že $a^{p-1} = 1$ v tělese $Z_p$
- vektorový prostor
  - je v něm definováno sčítání vektorů a násobení skalárem
  - je definován nad nějakým tělesem
  - vektorový prostor nad tělesem T je množina (V), s operacemi sčítání vektorů a násobení vektoru skalárem
    - musí splňovat 5 vlastností
      1. (V,+) je Ábelova grupa, neutrální prvek *o* a inverzní k v je -v
      2. násobení skalárem je asociativní (a×(b×v) = (a×b)×v)
      3. 1v = v (násobení vektoru neutrálním prvkem z T)
      4. distributivita pro skaláry (a×v + b×v = (a+b)×v)
      5. distributivita pro vektory (a×(u+v)=a×u+a×v)
  - tvrzení: vlastnosti vektorového prostoru
    - 0v = o
    - ao = o
    - av = o => a=0 v v=o
    - (-1)v = -v


#### 4. Základní vlastnosti konečně generovaných vektorových prostorů, vektorové podprostory. Báze a dimenze.
- vektorový podprostor
  - U je podmnožina V
  - U je podprostorem, když platí 3 podmínky:
    1. o ∈ U
    2. pro všechny vektory u,v z U platí, že u+v ∈ U
    3. pro všechny a ∈ T a u ∈ U platí, že au ∈ U
- věta: průnik vektorových prostorů je opět vektorový prostor
- lineární obal
  - definovaný pro množinu vektorů
  - nejmenší možný podprostor pro dané vektory
  - je actually definován jako průnik všech vektorových prostorů, které tuto množinu obsahují
- s tím se blízce pojí lineární kombinace vektorů
- věta: všechny lineární kombinace množiny vektorů tvoří vektorový prostor rovný lineárnímu obalu těchto vektorů
- lineární závislost
  - vektory jsou lineárně závislé, když by odebrání nějakého vektoru z množiny neovlivnilo vektorový prostor, který tato množina generuje
  - také se to dá popsat tak, že nějaký vektor z množiny je lineární kombinací ostatních vektorů
- báze
  - lineárně nezávislý systém generátorů (lineárně nezávislá množina vektorů generujících vektorový prostor)
  - věta: pro každý vektor u z vektorového prostoru, který má bázi v1,v2,...,vn platí, že existují jednoznačně dané koeficienty a1,a2,...,an takové, že
    - $u=\sum_{i=1}^na_iv_i$
    - jednoznačnost plyne z lineární nezávislosti vektorů báze
- souřadnice
  - na základě předchozí věty o jednoznačném určení koeficientu pro lineární kombinaci daného vektoru je možné definovat souřadnice 
  - Mějme vektorový prostor V s bází B = {v1,v2,...,vn}. Pak souřadnice vektoru u z V jsou koeficienty a1,a2,...,an, pro které platí, že $u=\sum_{i=1}^na_iv_i$. Vektor souřadnic se značí $[u]_B :=  (a1, a2,...,an)$.
  - pro souřadnice platí, že
    - $[av]_B = a[v]_B$ a 
    - $[u+v]_B=[u]_B+[v]_B$

- Steinitzova věta o výměně
  - lepší ve skriptech, ale v principu jde o to, že pokud máme lineárně nezávislý systém n vektorů, tak tyto vektory mohou nahradit v bázi vektorového prostoru n bazických vektorů
  - i z toho pak je důsledek, že všechny možné báze jednoho vektorového prostoru budou mít stejný počet vektorů
- dimenze vektorového prostoru
  - na základě tohoto poznatku můžeme definovat dimenzi
    - dimenze je velikost báze vektorového prostoru
  - pokud máme lineárně nezávislý systém vektorů z vp V o velikosti dimenze V, pak tento lineárně nezávislý systém vektorů je báze V
- tady na stránce 89 je super obrázek na znázornění různých podprostorů $R^3$
- spojení podprostorů
  - buďte U,V podprostory vektorového prostoru W
  - pak spojení vektorových podprostorů je definováno takto:
    - $U+V := {u + v: uϵU, vϵV}$
  - to dovysvětluje ještě tvrzení, že $U+V = span(U ∪ V)$
  - tzn., (poznámka pro mě, abych si to ujasnil)
    - $U∪V ⊆ U+V$
    - to popisuje i další věta
      - $dimU+dimV=dim(U+V)+dim(U ∩ V)$

#### 5. Lineární zobrazení.
> Lineární zobrazení. Základní vlastnosti, maticová reprezentace, skládání lineárních zobrazení.

- lineární zobrazení je funkce ($f$), která zobrazuje vektor ($u,v$) na jiný vektor ($w$) ($f: v → w$)
  - pro $f$ platí, že
    - $f(u+v) = f(u) + f(v)$
    - $f(αv) = αf(v)$ ($α$ je z tělesa nad kterým je vektorový prostor)

- maticové prostory
  - máme sloupcový prostor matice (prostor generovaný sloupci matice, jakoby to byly vektoru) (S(A))
  - řádkový prostor matice (to stejný jen pro řádky?) (R(A))
  - a jádro - prostor řešení rovnice Ax=o (značí se Ker(A))

- zajímavý point - součin Ax (x libovolný vektor odpovídající dimenze) dává množinu lineárních kombinací sloupců matice A
- pokud se podíváme na matici A v RREF tvaru, tak prvních r sloupců RREF(A) tvoří bázi vp S(A) (jsou lineárně nezávislé a generují celý prostor S(A)), r je hodnost matice A
- to celé dává pointu, že rank(A)+dim(ker(A))=n, pokud A je m×n
  - např. pokud je A regulární, n×n, tak rank(A) = n, ker(A) = 0
  - když je singulární, tak existuje alespoň jedna dimenze v ker(A) - vektory alespoň jedné dimenze matice A "pohltí" a pronásobí na 0


- maticemi je možné reprezentovat jakékoli lineární zobrazení
  - v rovině ($R^2$) jsou lineární zobrazení operace
    - překlopení (dá se udělat jako kombinace natažení s koeficientem $α=-1$ a rotace o 180˚)
    - natažení (mám pocit, že to bude matice $αI_n$, $α>0$)
    - rotace
      - speciálně pro rotaci je fajn vědět matici
      - $A=\begin{bmatrix}
        cos(α) & -sin(α) \\
        sin(α) & cos(α)
        \end{bmatrix}$
  - posunutí není lineární zobrazení!
- jádro zobrazení - $ker(f)$ - je množina vektorů z vektorového prostoru V, které zobrazení $f$ zobrazí na nulový vektor
- jádro zobrazení souvisí přímo s jádrem matice
  - pokud f(v) = Av, pak ker(f) = ker(A)
- pro každé lineární zobrazení existuje matice lineárního zobrazení, která toto zobrazení provede
- matice lineárního zobrazení
  - máme bázi vektorového prostoru U, $B_U$ a bázi V, $B_V$
  - když máme lineární zobrazení $f$, které zobrazuje vektory z U do V (vektorových prostorů), tak pro každý vektor x z U platí, že
    - existuje matice $_{B_V}[f]_{B_u}$ taková, že
      - $[f(x)]_{B_v} = _{B_V}[f]_{B_u}[x]_{B_U}$
    - matice $_{B_V}[f]_{B_u}$ tedy převádí souřadnice vektoru x na souřadnice jeho obrazu
    - tato matice je jenom jedna pro dané zobrazení
- matice přechodu
  - pro dané dvě báze existuje matice, která převede souřadnice vektoru v jedné bázi na souřadnice v druhé bázi
- isomorfismus
  - isomorfismus je vzájemně jednoznačné zobrazení pro vektorové prostory U, V
    - isomorfismus má inverzní zobrazení
    - dimenze prostorů s isomorfizmem je stejná (dim(U)=dim(V))
    - zobrazení složené ze dvou isomorfních zobrazní je také isomorfní
    - zobrazení je isomorfní právě tehdy, když se jakákoliv báze U zobrazí na nějakou bázi V
- pro počítání matice přechodu z jednoho VP do druhého je možné použít "mnemotechniku"
  - $([B_u]|[B_v])~^{RREF}([I_n]|_{B_v}[id]_{B_U})$
- věta o dimenzi jádra a obrazu
  - mějme f: U→V,
  - $B_U$ je báze U
  - $B_V$ je báze V
  - A = $_{B_V}[f]_{B_U}$
  - Pak
    - $dim(ker(f)) = dim(ker(A))$
    - $dim(f(U)) = dim(S(A))$
- to má důsledek, že dim(U) = dim(ker(f))+dim(f(U))
- důsledek - matice lineárního zobrazení
  - $f$ je prosté právě tehdy, když má matice zobrazení lineárně nezávislé sloupce
  - $f$ je "na" právě tehdy, když má matice lineárně nezávislé řádky

#### 6. Skalární součin a norma.
>Skalární součin a norma. Vlastnosti v reálném i komplexním případě, Cauchy-Schwarzova nerovnost. Kolmost. Ortogonální doplněk a jeho vlastnosti, ortogonální projekce.

- jde o operaci vektorů mezi sebou navzájem
- pro u,v z V nad T, a z T, u × v = a
  - standardní skalární součin: $x^Ty=∑_{i=0}^n x_i y_i$
  - z hlediska geometrie platí, že $x^Ty=||x||||y||cos(ϕ)$
- skalární součin ve vektorovém prostoru V nad R je zobrazení $<.,.>: V^2 → R$, které pro všechna x,y,z z V a α z R splňuje tyto 4 podmínky:
  1. $<x,x> ≥ 0$ a rovnost nastane jen pro x=0
  2. $<x+y,z> = <x,z> + <y,z>$
  3. $<αx,y>=α<x,y>$
  4. $x,y>=<y,x>$
- norma indukovaná skalárním součinem je odmocněný skalární součin sama se sebou
- kolmost: vektory jsou kolmé, když jejich skalární součin je nula
- pythagorova věta: spíš zajímavé, že má v tomhle kontexu docela jednoduchý důkaz
  - $||x+y||^2=<x+y,x+y>=<x,x+y>+<y,x+y>=<x+y,x>+<x+y,y>=<x,x>+<y,x>+<x,y>+<y,y>=$(($<x,y>=<y,x>=0$, protože $x,y$ jsou kolmé))$<x,x>+<y,y>=||x||^2+||y||^2$
- Cauchyho-Swarzova nerovnost
  - pro všechny x,y z V platí, že $|<x,y>|≤||x|| ||y||$
    - pro reálná čísla, standardní skalární součin a euklidovskou normu se dá nerovnost nahlédnout z toho, že víme, že $<x,y>=||x|| ||y|| cos(ϕ)$, přičemž $cos(ϕ)≤1$
- norma obecně
  - norma je zobrazení ||.|| vektoru do reálných čísel, které je vždy kladné, lineární pro násobení skalárem a splňující trojúhelníkovou nerovnost

- ortogonální a ortonormální systém vektorů
  - tyhle pojmy úzce souvisí s bázemi v otázce č. 4, např. vektory e1,e2 a e3 tvořící kanonickou bázi v.p. $R^3$ splňují obě vlastnosti
  - systém vektorů je
    - ortogonální, když jsou všechny vektory na sebe vzájemně kolmé
    - ortonormální, když mají všechny vektory normu 1 a navíc je systém ortogonální
- ortonormální vektory jsou vzájemně lineárně nezávislé
- ortogonalizace báze (Gram-Smidtova)
  - pro nějakou bázi se postupně vektory nakolmují (vezme se první, na něj se nakolmí druhý, třetí atd.) a po nakolmení se ještě normalizují (podělí vlastní normou)
  - používají se při tom Fourierovy koeficienty
  - máme bázi {x1,x2,x3}={(2,0,0), (-1,1,0), (0,1,2)}
    - nejprve upravíme první vektor
      - ten se nenakolmuje
      - y1 = x1
      - z1 = y1/||y1||=(1,0,0)
    - u druhého vektoru již využijeme nakolmení
      - $y_2 = x_2 - ∑_{i=1}^1<x_2,z_i>z_i = (-1,1,0)-(-1×(1,0,0)) = (0,1,0)$
      - z2 = y2/||y2|| = (0,1,0)
    - třetí vektor
      - $y_3 = x_3 -  ∑_{i=1}^2<x_2,z_i>z_i = (0,1,2)-(0×(1,0,0)+1×(0,1,0)) = (0,0,2)$
      - z3 = y3/||y3|| = (0,0,1)
    - vyšla tedy kanonická báze - cože je dané tím, že první vektor byl násobkem vektoru z kanonické báze. Kdybych začal s třeba x3, tak by výsledek dopadl jinak
- výrazu <x,z> pro vektor x a vektor z z ortonormálního systému vektorů se říká "Furierův koeficient"

- ortogonální doplněk
  - množina vektorů $M$ má ortogonální doplněk $M^⊥$ tvořený vektory kolmými na vektory množiny $M$
  - ortogonální doplněk má následující základní vlastnosti (M,N množina vektorů z V, $M^⊥$, vektorový prostor V):
    1. $M^⊥ ∩ V$
    2. pokud $M$ je podmnožina $N$, pak $N^⊥$ je podmnožina $M^⊥$
    3. $M^⊥$ je ortogonálním doplňkem vektorového prostoru generovaného $M$ ($span(M)$)

- ortogonální doplněk je možné definovat i pro vektorový protor
  - pokud U je podprostor vektorového prostoru V, tak platí
    1. pokud z1,z2,...,zm je ortonormální báze U a z1,...,zm+1,...,zn je rozšíření této báze na bázi V, pak zm+1,...,zn je báze U$^⊥$
    2. dimenze V je součtem dimenze U a jeho ortogonálního doplňku
    3. V = U + U$^⊥$
    4. $(U^⊥)^⊥=U$
    5. průnik U s jeho ortogonálním doplňkem je vektorový prostor pouze s nulovým vektorem

- ortogonální projekce
  - mějme vektorový prostor V a jeho podprostor U. Ortogonální projekce vektoru x z V do podprostoru U je jeho obraz x$_U$, který splňuje, že $||x-x_U||={min_{y ∈ U}(x-y)}$
- věta: existuje právě jedna projekce pro daný vektor
  - pokud je báze (z1,...,zn) prostoru U ortonormální, pak $x_U=∑_{i=0}^n <x,z_i>z_i$
  - 

- co tu chybí
  - ortogonální doplněk a projekce v $R^n$
  - ortogonální matice
  - metoda nejmenších čtverců



#### 7. Determinanty
>Determinanty. Definice a základní vlastnosti determinantu. Úpravy determinantů, výpočet.

- determinant je taková zvláštní vlastnost matice
- pomocí determinantu se dá spočítat inverzní matice k regulární matici
- zobrazení pomocí matice A mění "objem" objektu s koeficientem det(A) (délku/plochu/objem)

- mějme matici A, která je n×n a všechny permutace indexů $S_n={1,...,n}$
  - $det(A) = ∑_{pϵP_n}sgn(p)∏_{i=0}^{n}a_{ip(i)}$

- vlastnosti determinantu
  - $det(A) = det(A^T)$
    - to vyplývá z definice determinantu
  - obecně determinant součtu matic není roven součtu determinantů matic
    - platí ale tzv. řádková linearita determinantu
      - těžký přesně popsat slovy, matematicky:
        - $det(A+e_ib^T)=det(A)+det(A+e_ib^T-A_{i*})$
  - snadno se spočítá determinant trojůhelníkové matice
    - je roven pouze jednomu produktu, a to produktu prvků na diagonále, protože ostatní permutace použijí v produktu alespoň jednou nulu
      - pokud je matice A horní trojúhelníková, pak její determinant (det(A)) je možné spočítat jako $∏_{i=0}^{n}a_{ii}$
  - na základě toho, se vyplatí vědět, jak se mění determinant při převodu matice do REF, protože tím si matici převedeme na trojúhelníkovou
    - při elementární úpravě (matice A' je matice po provedení dané elementární úpravy)
      - vynásobení i-tého řádku koeficientem $α$
        - $det(A')=α×det(A)$
      - výměna i-tého a j-tého řádku
        - $det(A')=-det(A)$
    - pro výpočet determinantu pomocí převodu matice na REF tvar nám stačí si pouze pamatovat koeficient, kterým byl původní determinant přenásoben
  - matice A o rozměrech n×n je regulární právě tehdy, když $det(A)\neq 0$
  - součin determinantů matic A,B je roven determinantu součinu matic A,B
    - $det(A)×det(B)=det(AB)$
  - pro regulární matici ($det(A)\neq 0$) platí, že $det(A^{-1})=det(A)^{-1}$
  - výpočet determinantu pomocí Laplaceova rozvoje
    - determinant matice $A ϵ T^ {n×n}$, n>2 je možné spočítat tak, že pro vybraný (i-tý) řádek spočítáme součet determinantů matic vzniklých vyškrtnutím i-tého řádku a j-tého sloupce pro j=1,...,n a vhodným pronásobením, viz vzoreček
      - $det(A)=∑_{j=1}^{n}(-1)^{i+j}a_{ij}det(A^{ij})$
- Cramerovo pravidlo
  - řešení soustavy rovnic (Ax=b) je možné dát i explicitním vzorcem, přestože to není ve většině případů ten nejrychlejší způsob, jak najít řešení
    - Buď $A ϵ T^ {n×n}$ regulární
      - $b ϵ T^n$
      - $(A+(b-A_{*i})e_i^T)$ je matice A s nahrazeným i-tým sloupcem vektorem b
      - pak $x_i=\frac{det(A+(b-A_{*i})e_i^T)}{det(A)}$

- asi to nebude potřeba, ale dál učebnice uvádí adjugovanou matici
  - po prvcích je adjugovaná matice k matici A definována takto
    - $adj(A)_{ij}=(-1)^{i+j}det(A^{ij})$
      - $A^{ij}$ je opět matice A s vyškrtnutým i-tým a j-tým řádkem/sloupcem
    - je tam podobnost s laplaceovým rozvojem pravidlem (mnemotechnika)
    - zajímavý je výpočet inverzní matice, protože $A^{-1}=\frac{1}{det(A)}adj(A)$


#### 8.  Vlastní čísla a vlastní vektory matic
> Vlastní čísla a vlastní vektory matic. Výpočet a základní vlastnosti. Diagonální tvar matice, diagonalizovatelnost. Jordanův normální tvaru (v obecném případě).

- vlastní čísla představují další možnou charakteristiku matice
  - definice
    - pro matici $A ϵ C^{n×n}$
    - je číslo $λ ϵ C$ vlastním číslem matice A,
    - pokud existuje jemu příslušný vlastní vektor $x ϵ C^{n}$ tak, že platí
      - $Ax = λx$ a $x \neq o$

- vlastní čísla a vektory mají hezkou geometrickou interpretaci
  - vektor x se zobrazením pomocí matice A pouze prodlouží, či zkrátí a to právě λ-krát

- věta: charakteristika vlastního čísla a vektoru
  - pro matici a platí, že λ je vlastním číslem matice A právě tehdy, když $det(A-λI_n)=0$
  - x je vlastním vektorem právě tehdy, když náleží do $Ker(A-λI_n)$
- důsledkem této věty je, že k jednomu vlastnímu číslu náleží $n-rank(A-λI_n)=dim(Ker(A-λI_n))$ lineárně nezávislých vektorů

- vlastní čísla je možné získat zkombinováním znalostí vlastností vlastních čísel a determinantu
  - $det(A-λI_n)=0$ -> rozepsáním definice determinantu získáme rovnici, kterou je možné převést na tzv. charakteristický polynom matice A
  - $p_A(λ)=det(A-λI_n)$
  - $det(A-λI_n) = (-1)^{n}λ^{n}+a_{n-1}λ^{n-1}+...+a_1λ+a_0$
    - tady jsem nepochopil to převedení na polynom takhle přímočaře, ale v principu to nevadí..

- výpočet vlastních čísel pomocí charakteristického polynomu
  - příklad
    - $$A = \begin{bmatrix}
        0 & -2 \\
        2 & 0
        \end{bmatrix}
        $$
    - $$A-λI_n = \begin{bmatrix}
      -λ & -2 \\
       2 &  -λ
      \end{bmatrix}
      $$
    - $det(A - λI_n) = λ^2 + 4$
    - kořeny jsou $\plusmn2i$, což jsou i vlastní čísla matice (obor komplexních čísel)
- spektrum a spektrální poloměr
  - spektrum je množina vlastních čísel matice
  - spektrální poloměr je (v absolutní hodnotě) největší vlastní číslo
- algebraická a geometrická násobnost vlastního čísla
  - algebraická násobnost je násobnost λ, kořene charakteristického polynomu
  - geometrická násobnost je počet lineárně nezávislých vlastních vektorů (tedy pro matici n×n je rovno $n-rank(A-λI_n)$)
  - algebraická násobnost je vždy větší/rovna geometrické násobnosti
- vlastní čísla trojúhelníkové matice jsou prvky matice na diagonále
- tvrzení
  - det(A)=λ1×λ2×...×λn
  - trace(A)=λ1+λ2+...+λn
    - trace(A)=a11+a22+...ann
- typy a úpravy matic a vlastní čísla
  1. ekvivalence - vlastní číslo je nula a matice je singulární
  2. matice je regulární, inverzní matice má vlastní čísla jako inverzní prvky k původním, vlastní vektory se nezmění
  3. umocnění matice umocní vlastní čísla, vlastní vektory se nezmění
  4. přičtení násobku jednotkové matice k matici zvýší vlastní čísla o tento násobek
  5. násobení matice skalárem vynásobí skalárem vlastní čísla
  6. transpozice matice zachová vlastní čísla, ale může změnit vektory
- platí, že pokud vlastní číslo λ je komplexní číslo, pak i komplexně sdružené číslo k λ je vlastní číslo matice

- matice společnice
  - ukazuje převoditelnost problému hledání kořenů polynomu na problém hledání vlastních čísel matice
  - mějme polynom $p(x)=x^n+a_{n-1}n^{n-1}+...a_1x+a_0$
  - pak matice společnice je definovaná tak, že na pozicích $C_{2,1}$ až $C_{n,n-1}$ jsou jedničky a v pravém sloupci jsou sestupně koeficienty $a_i$ (hezčí je obrázek na str. 175), v prvním řádku je $a_{n-1}$ a v posledním řádku $a_0$


- Cayleyho-Hamiltonova věta
  - přeskakuji, není v otázce

- diagonalizovatelnost
  - pokud se povede diagonalizovat matici, pak její vlatní čísla v této podobě můžeme přímo vyčíst z diagonály matice
  - nejdřív se ale definuje podobnost
    - matice A a B jsou si "podobné", pokud existuje regulární matice S tak, že $A = SBS^{-1}$
  - věta: podobné matice mají stejná vlastní čísla
  - věta: podobné matice mají stejný počet lineárně nezávislých vlastních vektorů
  - matice je diagonalizovatelná, pokud se podobá nějaké diagonální matici
    - tedy $A = SΛS^{-1}$, kde S je regulární a  diagonální
  - věta: matice je diagonalizovatelná právě tehdy, když má $n$ lineárně nezávislých vlastních vektorů
    - pokud známe vlastní vektory a vlastní čísla matice A, tak matici S sestavíme jako vektory (podle sloupců) a matici Λ bude mít pouze vlastní čísla na diagonále (tak, aby odpovídaly vlastním vektorům)
    - pokud má matice n navzájem různých vlastních čísel, pak je diagonalizovatelná
  - pokud je matice diagonalizovatelná, pak má mnoho fajn vlastností
    - např. $A^k = S Λ^ kS^{-1}$
    - pomocí diagonalizovatelných matic se dají (mocněním diagonální matice) řešit rekurzivně zadané posloupnosti

- Jordanova normální forma
  - "nejjednodušší tvar matice pro podobnost"
  - Jordanova buňka
    - pro komplexní číslo λ a
    - přirozené číslo k
    - je Jordanova buňka $J_k(λ)$ čtvercová matice řádu k
      - má tvar, že pokud i=j, je tam λ
      - a jednu buňku nad λ je jednička, pokud i není 1 
        - možná lepší, pokud indexy i=j+1, je tam jednička
  - Jordanova normální forma
    - matice je v Jordanově normální formě, pokud má na diagonále jako podmatice Jordanovy buňky, jinak má všude 0
    - věta: každá matice má k sobě podobnou matici v Jordanově normální formě. Tato matice je až na pořadí Jordanových buněk jednoznačná
    - počet vlastních vektorů je roven počtu Jordanových buněk




### 3. Kombinatorika, pravděpodobnost a statistika
- materiály na učení
  - zkusím, co půjde, brát z ["Kapitol z diskrétní matematiky"](https://drive.google.com/drive/u/2/folders/0BzEbjnxrwP6Ob0lCMGFoRXZldG8?resourcekey=0-mbJ_xaUndffDgaZGjEh0XA) (na Bioinformatickym GDrivu)
  - zbytek asi doberu z Wikipedie, pamatuju si, že mi v prváku některé věci z učebnice nějak nedávaly smysl
  - toky v sítích jsem musel vzít z jiných zdrojů, konkrétně z [webovek Martina Kouteckého](https://research.koutecky.name/db/teaching:kg12021_prednaska) (je to 7-8 přednáška na uvedené stránce)

#### 1. Binární relace, ekvivalence a částečná uspořádání. Kombinatorické počítání: kombinační čísla, binomická věta, princip inkluze a exkluze.
- binární relace
  - ekvivalence/uspořádání
  - binární relace je zavedená na nějaké množině
  - prvky množiny tuto relaci buďto splňují, nebo nesplňují
  - prvky množiny mohou být např. další množiny nějakých prvků, např.
    - A={1,2,3,4}
    - B={4,3,2,1}
    - C={1,3}
    - D={1,5,6,7}
  - relace mohou mít čtyři základní vlastnosti:
    - jsou reflexivní
    - jsou symetrické
    - jsou antisymetrické
    - jsou tranzitivní
  1. reflexivita - prvek množiny je v relaci sám se sebou
    - např. $A\subseteq A$
    - např. "nebýt podmnožinou" není reflexivní, protože množina nemůže nebýt podmnožinou sama sebe
  2. symetrie
    - pokud platí, že v relaci ("R(.,.)") je jsou např. R(A,D), pak relace platí i pro R(D,A)
      - např. relace "obsahuje stejný počet prvků" - |A|=|D| je symetrická
      - naopak
  3. antisymetrie
    - jediný případ, kdy platí symetrie je, když je relace na prvku sama se sebou (např. A=A)
    - tady jsem trochu vždycky nechápal, kde je to odlišení od symetrie, ale je to v tom, že u symetrie musí to prohození fungovat úplně vždycky (R(a,b) => R(b,a) pro všechna a,b), zatímco antisymetrie funguje jen pro ten stejný prvek
  4. tranzitivita
    - když relace platí mezi a-b a b-c, platí mezi a-c
  - ekvivalence 
    - kategorie relací, které dávají něco jako zobecněnou rovnost - např. "množiny mají stejnou velikost" nebo "předměty mají stejnou barvu"
    - ekvivalence jsou všechny relace, které jsou reflexivní, symetrické a tranzitivní
  - (částečné) uspořádání
    - je to něco jako zobecněné porovnávání prvků
    - např. "být podmnožinou" je částečné uspořádání
    - musí splňovat reflexivitu, antisymetrii a tranzitivitu
    - to "částečné" znamená, že nejde porovnat každý prvek množiny s každým
      - např. pro množiny A-C mohu říct, že $A\subseteq C$, ale pro A-D nemůžu říct ani že $A\subseteq D$, ani že $D\subseteq A$
      - například $\geq$ na reálných číslech je úplné uspořádání - pro každá dvě čísla mohu říct, které je větší/rovno tomu druhému
        - rovnost nastane pouze pokud jsou čísla stejná - antisymetrie
  - trochu se rozepisuju ... pro mě je důležitý si ty pojmy ujasnit, i když jejich obsah je docela intuitivní...
  - ještě je fajn zmínit **Hasseův diagram**, což je zobrazení částečně upořádané množiny, v učebnici v něm ukazovali příklad na množině 1,2,...,10 a relaci "dělitelnost"

- kombinatorické počítání
  - s pojmem kombinatorického počítání souvisí pojmy 
    - permutace,
    - variace a
    - kombinace
  - jde o pojmy pro různé typy uspořádaných a neuspořádaných k-tic prvků dané množiny
  - **permutace**
    - na množině (A) jsou všechny uspořádané n-tice prvků A, přičemž n = |A|
    - pro A={1,2,3} jsou permutace
      - (1,2,3),
      - (1,3,2),
      - (2,1,3),
      - (2,3,1),
      - (3,1,2),
      - (3,2,1)
    - velikost množiny všech permutací prvků množiny A je $n!$
  - **variace**
    - jsou uspořádané k-tice prvků z množiny (A), $k\leq n=|A|$
    - pro A={1,2,3} a k=2 jsou variace
      - (1,2)
      - (1,3)
      - (2,1)
      - (2,3)
      - (3,1)
      - (3,2)
    - velikost množiny variací je $\frac{n!}{n-k!}$
    - tohle byly variace bez opakování, pro variace s opakováními (každý prvek může být použit i vícekrát) platí vzoreček $n^k$ - pro příklad výše by přibyly ještě (1,1), (2,2), (3,3)
  - kombinační čísla,
    - něco jako variace bez opakování, které nejsou navíc uspořádané ({1,2}={2,1})
    - vlastně stačí podělit vzoreček pro variaci ještě počtem permutací k prvků, což je k!
    - počet prvků v množině kombinací je $\frac{n!}{k!(n-k)!}$, což se značí $n\choose k$
      - možná je kvůli dalšímu matfyzovýmu používání lepší znát formulku pro kombinační čísla $\frac{\prod_{i=0}^{n-k}(n-i)}{k!}$
    - pro A jsou kombinace pouze 3
      - {1,2}
      - {1,3}
      - {2,3}
    - pro kombinační číslo platí několik základních vztahů
      - $n \choose 0$ $= \frac{n!}{0!×(n-0)!} =$ $n\choose n$ $=\frac{n!}{n!×(n-n)!}$ $=1$
      - $n \choose k$$=$$n \choose n-k$
      - $n \choose k$$+$$n \choose k+1$$=$$n+1 \choose k+1$
      - tohle je dobře vidět u [Pascalova trojúhelníku](https://cs.wikipedia.org/wiki/Pascal%C5%AFv_troj%C3%BAheln%C3%ADk)
- binomická věta
  - ještě je fajn zmínit, že množinu všech k-prvkových podmnožin množiny (X) značíme $X \choose k$ a její velikost je pro n=|X| rovna $n\choose k$
  - binomická věta v základu říká, že
    - $(a+b)^n = \sum_{k=0}^n$$n \choose k$$a^kb^{n-k}$
      - např. $(a+b)^3 = a^3×b^0 + a^2b^1 + a^1b^2 + a^0b^1$
- princip inkluze a exkluze
  - pro množiny s konečným počtem prvků A,B platí, že
    - $|A \cup B| = |A|+|B|-|A \cap B|$
    - tohle se dá zobecnit
      - nechce se mi vzoreček rozepisovat (je v učebnici na str. 84)
      - jde o to, že se pro lichý počet množin průniky lichých k-tic množin přičítají a sudých k-tic odčítají a naopak

#### 2. Teorie grafů. Základní pojmy teorie grafů: grafy a podgrafy, izomorfismus. Stromy a jejich základní vlastnosti, kostra grafu.
- Základní pojmy teorie grafů grafy a podgrafy
  - graf G je dvojice (V,E), kde V je neprázdná množina a E je množina hran
    - $v_1,v_2,...,v_n ∈ V$ jsou vrcholy
    - dvojice $e_{ij}=\{v_i,v_j\}∈E$, i,j ∈ {1,2,...,n}, i!=j (pro neorientované grafy bez hran sama na sebe) jsou hrany
      - dvoubodové podmnožiny V
  - podgraf H=(V',E') je podgrafem grafu G=(V,E), pokud $V'\subseteq V$ a $E' \subseteq E$
    - hrany E' jsou tvořeny pouze vrcholy z V' ($E' \subseteq E \cap$$V' \choose 2$)
    - H je indukovaným podgrafem G, pokud jsou zachovány všechny hrany, které mohly být zachovány ($u,v ϵ V':\{u,v\} ϵ E \implies \{u,v\} ϵ E'$)
    - 
- izomorfismus
  - dva grafy (G,G') nazveme *izomorfní*, jestliže existuje vzájemně jednoznačné zobrazení $f : V \rightarrowtail V'$, že platí {x,y}∈E právě tehdy, když {f(x),f(y)}∈E'
- možná se vyplatí i vědět pojmy jako
  - vrcholová souvislost
    - (počet vrcholů, které je potřeba odebrat, aby se graf rozpadl na dvě komponenty)
  - hranová souvislost
  - stupeň vrcholu
    - (počet hran z vrcholu)
- Stromy a jejich základní vlastnosti
  - strom je souvislý graf bez cyklu
  - možná fajn vědět pojmy
    - tah
      - pro $v_0,v_1,...,v_t ϵ V$ a $e_1,e_2,...,e_t ϵ E$ ($e_i = \{v_{i-1},v_i\}$)
      - pro $i \neq j$ platí, že $e_i \neq e_j$
      - je tah posloupnost $(v_0,e_1,v_1,...,e_t,v_t)$
        - v tahu se tedy nemohou opakovat hrany, ale mohou se opakovat vrcholy
        - tah je např., když se kreslí na jeden pokus takovej ten domeček na 5 vrcholech
    - cesta
      - jako tah, jen se tam nesmí opakovat ani vrcholy
    - cyklus
      - jako cesta, jenom $v_0 = v_t$
    - délka hrany - funkce dávající každé hraně číselnou hodnotu
    - algoritmus pro nejkratší cestu
      - Dijkstrův algoritmus
  - lemma: strom (mající alespoň dva vrcholy) má alespoň 2 vrcholy stupně 1 (koncové vrcholy, říká se jim *list*)
  - tvrzení: pokud G je graf a v ∈ G je list pak G je strom právě tehdy, když G-v je také strom
  - věta: charakterizace stromu
    - následují je ekvivalentní:
    - G je strom
    - G je souvislý a vynecháním libovolné hrany vznikne nesouvislý graf
    - pro každé dva vrcholy z G existuje právě jedna cesta
    - G neobsahuje kružnici a když se přidá mezi libovolnými dvěma vrcholy G hrana, tak vzniklý graf bude mít kružnici
    - G je souvislý a platí Eulerův vzorec: |V|=|E|+1

- kostra grafu
  - kostra grafu G je jeho podgraf, který je zároveň strom
    - je vidět, že G má kostru právě tehdy, když je souvislý
      - strom musí splňovat souvislost + vznikne jen odstraňováním hran z G
      - kostra obsahuje jen hrany, které v G už byly, takže protože strom je souvislý tak i G musí být souvislý
    - kostra se docela snadno konstruuje
      - vezmeme vrcholy z G a postupně k nim budeme (v jakémkoliv pořadí) přidávat hrany
      - pokud vznikne přidáním nějaké hrany kružnice, zahodíme ji a pokračujeme s dalšími
      - po projití všech hran máme kostru grafu G (pokud byl graf souvislý)
    - můžeme řešit problém minimální kostry
      - vtipné je, že na to funguje hladový Kruskalův algoritmus
        - hrany se seřadí podle velikosti
        - provede se výše zmíněný algoritmus na vytváření kostry grafu v pořadí hran od nejmenší do největší
  - počet koster na úplném grafu
    - popisuje Cayleyho formule (asi důležitý vědět)
      - k ní je spoustu důkazů
      - pro kompletní graf na n vrcholech $\kappa(n)$ platí, že počet stromů tohoto grafu je roven $n^{n-2}$
        - říkal jsem si, že bych rád uměl aspoň ten důkaz Cayleyho formule s obratlovcema, tak ho tu zkusim reprodukovat

- obratlovčí důkaz Cayleyho formule
  - máme úplný graf $\kappa(n)$ o n vrcholech
  - obratlovec je kostra grafu s jedním vrcholem označeným čtvercem a jedním jako kolečkem
  - množina $O$ označuje všechny obratlovce
  - každá jedna kostra má $n^2$ obratlovců
  - počet koster je tedy $\frac{|O|}{n^2}$
  - teď se využije lemma, které se dokáže potom
    - mezi zobrazením množiny všech zobrazení vrcholů V sama na sebe (je jich tolik, kolik je variací s opakováním délky n pro n prvků, tedy $n^n$) a množinou všech obratlovců existuje bijekce ($F$)
  - z bijekce vyplývá, že počet zobrazení vrcholů V na sebe je stejný, jako počet všech obratlovců, tedy $|O|=n^n$
  - protože počet koster známe, můžeme dosadit $\frac{|O|}{n^2}=\frac{n^n}{n^2}=n^{n-2}$. $\square$
  - hmhm. to lemma je docela velký, nechce se mi to rozepisovat.
  - cílem je ukázat, že každý obratlovec dané kostry má k sobě právě jednu permutaci vrcholů a že z každé permutace je možné zpětně zkonstruovat toho obratlovce, přičemž tam platí bijekce
    - důkaz je vlastně konstruktivní, ukazuje se způsob, jak pro každého obratlovce udělat zobrazení
    - postup je takový, že se nejprve udělá zobrazení vrcholů z "páteře", tedy cesty z kroužku do čtverečku, sama na sebe (permutace), a pak se zobrazí každý další vrchol směrem na vrchol co jde k páteři
    - jen se ještě musí dokázat, že teda každé zobrazení má obratlovce, který se z něj dá rekonstruovat


#### 3. Rovinné grafy, barvení grafů. Toky v sítícha aplikace. Souvislost grafů (míra souvislosti), Mengerovy věta.¨
- Rovinné grafy
  - graf můžeme "nakreslit" do roviny
  - nakreslení je funkce, která každému vrcholu grafu z množiny V přiřadí bod b(v) v rovině a každé hraně z E přiřadí v rovině oblouk (křivku?) o(e)
  - Kuratowského věta
    - graf je rovinný právě tehdy, když není isomorfní dělení grafu $K_{3,3}$ ani $K_5$

- barvení grafů
  - rovinné grafy jde obarvit 4 barvami
    - dost složitý důkaz
    - pro 5 barev není důkaz složitý
  - obarvení je funkce, která každému vrcholu grafu přiřazuje prvek z množiny {1,2,...,k}, žádná hrana nesmí spojovat dva vrcholy stejné barvy
  - barevnost grafu, značí se k(G), je minimální počet barev potřebných k obarvení grafu G

- toky v sítích a aplikace
  - v principu jsou toky definované na orientovaných grafech (hrany mohou být dané v případě potřeby tam i zpátky)
  - kapacita toku je funkce, která dává každé hraně v grafu nezápornou hodnotu
  - zdroj a stok jsou dva specifické vrcholy
  - tok je funkce, která každé hraně dá hodnotu, která bude mezi 0 a její kapacitou
    - pro každý uzel kromě zdroje a stoku musí navíc platit, že kolik do něj vstoupí, tolik musí i vystoupit
      - tahle vlastnost se jmenuje 1. Kirhofův zákon
      - pro zdroj platí, že z něj vystupuje více/rovno, než do něj vstupuje
      - pro stok platí naopak, že do něj vstupuje více/rovno, než do něj vstupuje
  - "Síť" je čtveřice (G,z,s,c)
    - G je orientovaný graf
    - z,s ϵ V(G)
    - $c: E(G) → ℝ\geq0$
  - "Tok" je funkce $f:E(G)→R\geq0$, která splňuje následující podmínky
    1. pro každou hranu e platí, že $f(e) \leq c(e)$
    2. pro každý vrchol $vϵV(G)-\{z,s\}$ platí, že $\sum_{(x,v)ϵE(G)}f(x,v)=\sum_{(v,y)ϵE(G)}f(v,y)$ 
  - "velikost toku" je to, co odtéká ze zdroje bez toho, co do něj přitéká
  - "maximální tok" - existuje
  - řez je množina hran, které rozdélí graf tak, že nevede žádná cesta ze zdroje do stoku
  - kapacita řezu
    - kolik je součet kapacit na řezu
  - maximálmní tok grafu je roven kapacitě nejmenšího řezu
  - Ford-Fulkersonův algoritmus
    - hledání maximálního toku
    - opakovaně se najde nenasycená cesta a nasytí se
    - pro racionální čísla najde vždy maximální tok

- Souvislost grafů (míra souvislosti)
  - hranový řez je množina hran $F \subseteq G$, jejichž odstraněním z grafu přestane být graf souvislým
    - vrcholový řez podobně pro vrcholy, $A⊆G$
  - hranová souvislost
    - velikost minimálního hranového řezu
  - kritická souvislost - odebrání libovolného vrcholu/hrany sníží souvislost (např. stromy jsou hranově kriticky 1-souvislé)
  - $k_v(G) \leq k_e(G)$
  - $k_e(G)-1 \leq k_e(G-e) \leq k_e(G)$
  - Ford-Fulkersonova věta - pro G t.ž. $k_e(G) = k$ existuje právě $k$ hranově disjunktních cest

- Mengerova věta: G je $k_v(G)\geq t$ vrcholově souvislý právě tehdy, když mezi každými dvěma vrcholy existuje $\geq t$ vrcholově disjunktních cest
  - dokazuje se trikem z Ford-Fulkersonovy věty
    - každý vrchol se nahradí dvěma - jeden vstupní a druhý výstupní - a mezi nimi je hrana kapacity 1
      - tím se problém převede na problém hranové souvislosti



#### 4. Pravděpodobnost a statistika 
> Náhodné jevy, podmíněná pravděpodobnost, nezávislost náhodných jevů. Náhodné veličiny, střední hodnota, linearita střední hodnoty. Bodové odhady a testování hypotéz.

- literatura
  - používám skripta z předmětu PaSt I. od Roberta Šámala, jsou na [GDrivu](https://drive.google.com/drive/u/2/folders/1R81slCRWpVnEALIiYgbiQjoGgATiVhIB)

- náhodné jevy
  - tady asi stojí za to definovat pravděpodobnostní prostor
    - $\Omega$ je množina elementárních jevů
    - $F \sube \Phi(\Omega)$ je prostor jevů ($\Phi(\Omega)$ je potenční množina $\equiv$ prostor všech možných jevů)
    - $P$ je funkce: $P: F → [0,1]$ - zobrazuje prvky z prostoru jevů na reálné číslo od 0 do 1 tak, že
      - $P(\Omega)=1$ a
      - pravděpodobnost sjednocení po dvou disjunktních jevů je rovna součtu jejich pravděpodobností (jev je množina podmnožina množiny elementárních jevů)
    - pravděpodobnostní prostor je trojice $(\Omega, F, P)$
  - příklady pravděpodobnostních prostorů
    - klasický - konečná množina elementárních jevů, každý elementární jev má stejnou pravděpodobnost
    - diskrétní - konečná množina elementárních jevů, jednotlivé prvky množiny mají různé pravděpodobnosti
    - geometrický - $\Omega \sube \Reals^n$, pravděpodobnost je daná přímo úměrně k velikosti vybrané množiny jevů - např. v dim 1 je to uniformní rozdělení

- podmíněná pravděpodobnost
  - pravděpodobnost jevu A za podmínky, že platí jev B
  - $P(A|B)=\frac{P(A\cap B)}{P(B)}$
  - 

- nezávislost náhodných jevů
  - jevy jsou nezávislé, pokud $P(A\cap B) = P(A)P(B) \equiv P(A|B) = P(A)$

- náhodné veličiny
  - diskrétní náhodná veličina
    - funkce $X : \Omega \rightarrow \Reals$
      - pokud Im(X) je spočetná a
      - pro všechna $x \in \Reals:X^{-1}(x) \in F$
        - (F je prostor jevů)
        - ((tady je pro mě trochu confusing to "všechna x" - jakože asi to nechápu, jak to je napsaný ve skriptech. Na wiki píšou, že dnv je v praxi definovaná jako funkce, která každýmu prvku z elementárních jevů dá bod na reálné ose...))
  - pravděpodobnostní funkce
    - $px: \Reals \rightarrow [0,1]$
      - px(x)=P({X=x})
  - označení X=x je množina, která pro reálné číslo x obsahuje prvky z množiny elementárních jevů, které se na x zobrazí pomocí náhodné veličiny X ($\{x=X\} = \{ \omega \in \Omega : X(\omega) = x \}$)
    - tohle bylo pro mě na statistice dost confusing zapsání, takže to tu mám potřebu dát explicitně :D
  - pravděpodobnost px(x)=P({X=x}) se běžně zapisuje pouze jako P(X=x)

  - Bernoulliho (alternativní) rozdělení
    - náhodná veličina,
    - pro x=1 je pravděpodobnost p,
    - pro x=0 je pravděpodobnost 1-p,
    - pro x>1 je pravděpodobnost 0
      - p je parametr [0,1]
      - např. pravděpodobnost, že při jednom hodu kostkou padne 6 je 1/6, tedy p=1/6
      - pokud by mince nebyla cinklá, tak číslo kolikrát padne panna při jednom hodu je také dána Bernoulliho rozdělením, p=0.5
    - střední hodnota je p
  - Geometrické rozdělení
    - $P(X=x)=p×(1-p)^x-1$ pro x=1,2,3,...
      - pro jiná x je P(X=x)=0
    - pravděpodobnost, že v x-tém bodu padla šestka poprvé
    střední hodnota 1/p
  - Binomické rozdělení
    - pro x=k={0,1,...,n} je pravděpodobnost
    - $px(k)=$$n \choose{} k$$p^k × (1-p)^{n-k}$
      - p je pravděpodobnost jednoho úspěšného pokusu
    - např. pravděpodobnost k-úspěšných hodů pro n-celkových hodů
    - střední hodnota je np
  - hypergeometrické
    - taháme n míčků z krabice, kde je celkem N míčků, z toho K červených
    - jaká je pravděpodobnost, že vytáhneme právě k červených míčků? ($0\leq k\leq n\leq N$, $k<K$)
      - $p_X(k)=($$K \choose k$$N-K \choose n-k$$)/$$N \choose n$
      - E(X)=$\frac{nK}{N}$
  - Poissonovo rozdělení
    - např. kolik přijde emailů za hodinu
    - parametr $\lambda$
    - $p_X(k) = \frac{\lambda^k}{k!}e^{-\lambda}$
    - střední hodnota $\lambda$

- střední hodnota
  - pro danou diskrétní náhodnou veličinu je definována jako
    - $E(X) = \sum_{x\in Im(X)}x×P(X=x)$
  - platí pro ní linearita
    - tzn. E(a.X + b) = a.E(X) + b
    - a E(X+Y) = E(X) + E(Y)

- rozptyl
  - $var(X) = E((X-E(X))^2)$
    - pro DNV se počítá prakticky pomocí sumy
      - $var(X) = \sum_{x \in Im(X)} (x-E(X))^2$
- směrodatná odchylka
  - odmocnina z rozptylu

- spojité náhodné veličiny
  - podobně jako diskrétní
  - každý bod má samostatně nulovou pravděpodobnost, počítá se s pravděpodobností v intervalu
    - kumulativní distribuční funkce (CDF, značí se většinou $F_X$) pro danou veličinu je něco jako primitivní funkce, jen k funkci rozdělení dané veličiny
    - CDF je definovaná i pro diskrétní náhodné veličiny
  - funkce pravděpodobnosti se nazývá "hustota náhodné veličiny" (PDF, značí se $f_x$) a definuje se jako
    - $F_X(x) = \int_{-\infty}^x f_X(t) dt$
  - střední hodnota je definována jako integrál
    - $E(X)=\int_{-\infty}^{\infty}xf_X(x)dx$
  - rozptyl
    - $var(X)=E(X-E(X)) = \int_{-\infty}^{\infty} (x-E(X))^2 dx$
      - u rovnosti se využívá "pravidlo naivního statistika", že střední hodnota veličiny v nějaké funkci je přímočaře výpočet střední hodnoty z definice s hodnotami veličiny upravené podle té funkce
- spojitá rozdělení
  - uniformní rozdělení
    - pro interval od a do b je konstantní pravděpodobnost
    - PDF je f(x)=1/(b-a)
    - CDF je
      - (x-a)/(b-a) pro x z [a,b]
      - 0 pro x<a
      - 1 pro x>b
    - E(X) = (a+b)/2
  - exponenciální rozdělení
    - PDF(x)
      - 0 pro x<0
      - $1-e^{-\lambda x}$
  - normální rozdělení (asi nejčastěji využívané)
    - standardní rozdělení
      - $PDF(x) = \phi(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}$
    - obecné normální rozdělení
      - značí se $N(\mu,\sigma^2)$
        - $\mu$ je střední hodnota
        - $\sigma$ je směrodatná odchylka
        - vlastně se jen přeškáluje obecné normální rozdělení
          - $N(\mu,\sigma^2)(x) = \frac{\phi(\frac{x-\mu}{\sigma})}{\sigma}$

- kvantilová funkce
  - značí se $Q_X(p)$
  - dává pro danou pravděpodobnost nejnižší hodnotu x z X takovou, že $p \leq F_X(x)$
  - u spojitých rozdělení je to inverzní funkce k CDF
  - medián je Q(0.5)
  - n-tý kvartil je Q(n/4)
  - n-tý percentil je Q(n/100)
  - atd.

- nerovnosti
  - Markovova
    - na wiki se jmenuje "Čebyševova nerovnost I. typu"
    - pro náhodnou veličinu X a $\epsilon>0$ platí
      - $P(X>\epsilon) \leq \frac{E(X)}{\epsilon}$
  - Čebyševova
    - na wiki "Čebyševova nerovnost II. typu"
    - pro náhodnou veličinu X a $\epsilon>0$
      - $P(|X-E(X)<\epsilon) \geq \frac{var(X)}{\epsilon^2}$

- statistika
  - náhodný výběr
    - posloupnost n.n.v. $X_1,X_2,...,X_n$ se stejným rozdělením

- intervalové odhady nejsou v otázce zahrnuty...

- bodové odhady
  - pro náhodný výběr X1,X2,...,Xn ~ Fθ, parametr $\theta$ a funkci g nazveme bodový odhad $\Theta_n$
    - nevychýlený, pokud $E(\Theta_n)=g(\theta)$
    - asymptoticky nevychýlený, pokud $lim_{n\rightarrow\infty}E(\Theta_n)=g(\theta)$
    - konzistentní, pokud $\Theta$ jde k $g(\theta)$ v pravděpodobnosti
  - vychýlení - rozdíl mezi $E(\Theta)$ a skutečnou hodnotu parametru $\theta$
  - střední kvadratická chyba (MSE)
    - $MSE(\Theta_n)=E((\Theta-\theta)^2)$
  - máme tři základní výběrové bodové odhady
    1. výběrový průměr $X̄_n = \frac{1}{n} \sum_{i=1}^n X_i$
    2. výběrový rozptyl 1 - $S_n^2 = \frac{1}{n} \sum_{i=1}^n (X_i-X̄_n)^2$  
    3. výběrový rozptyl 2 - $\^S_n^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i-X̄)^2$
  - $X̄_n$ je konzistentní a nestranný odhad střední hodnoty
  - $\^S^2_n$ je konzistentní a nestranný odhad rozptylu
  - $\^S^2_n$ a $S_n^2$ jde mezi sebou převádět pomocí tzv. Besselovy korekce - to je pronásobení členem $\frac{n}{n-1}$
- metoda momentů
  - 1. moment je střední hodnota
  - 2. z momentu se počítá rozptyl
  - 3. z momentu se počítá šikmost (skewness)
  - 4. z momentu se počítá špičatost (curtosis)
  - $m_r(\theta):=E(X^r)$ ... r-tý moment náhodné veličiny $X$
  - $\^m_r(\theta):=\frac{1}{n}\sum_{i=1}^n X_i^r$ ... r-tý výběrový moment náhodné veličiny
    - $\^m_r(\theta)$ je konzistentní nestranný odhad $m_r(\theta)$
  - pro střední hodnotu se tedy pomocí metody momentů odhadne tak, že vezmeme výběr hodnot, dáme je do vzorečku pro $\^m_1(\theta)$, což je to stejné jako výběrový průměr, tedy $\frac{1}{n} \sum_{i=1}^n X_i$
  - pro rozptyl využijeme to, že $E(X^2)=var(X)+E(X)$
    - to dává, že $var(X) = E(X^2)-E(X)$, tedy odhadneme pomocí prvního a druhého momentu ... $\^m_2(\theta) - \^m_1(\theta)$ (což mch. je ale výběrový rozptyl 1, $S_n^2 = \frac{1}{n} \sum_{i=1}^n (X_i-X̄_n)^2$)
  - upřímně - v téhle fázi jsem nepochopil, proč by mě měla metoda momentů zajímat, ale tak co už
- metoda maximální věrohodnosti (maximal likelihood)

- Studentův t-test
  - intervalový odhad náhodné veličiny
  - věta
    - X1,X2,...,Xn je náhodný výběr z $N(\mu,\sigma^2)$. Parametr $\theta=(\mu,\sigma)$ neznáme, určujeme $\sigma$.
    - $\alpha \in (0,1)$,
    - Studentovo t-rozdělení s n-1 stupni volnosti má CDF $\Psi_{n-1}$, hodnota $t_{\alpha/2}$ je definována tak, že $\Psi_{n-1}(t_{\alpha/2})=1-\alpha/2$
    - nechť $\delta = t_{\alpha/2}\frac{\^S_n}{\sqrt{n}}$
    - a nechť $C'''''''_n=[X̄_n-\delta,X̄_n+\delta]$
    - pak $P(\mu \in C'_n)\geq 1-\alpha$

- testování hypotéz
  - máme dvě hypotézy
    - $H_0$ ... nulová hypotéza, to, co předpokládáme
    - $H_1$ ... alternativní hypotéza
  - hladina významnosti ($\alpha$)
    - pokud je pravděpodobnost naměřeného jevu nižší, než hladina významnosti za nulové hypotézy, tak nulovou hypotézu musíme odmítnout
    - dále se označuje jako $1 - \beta$ "síla testu", tedy pravděpodobnost, že naměřená data nejsou z kritického oboru (to, že máme zamítnout nulovou hypotézu), za předpokladu, že platí alternativní hypotéza (pravděpodobnost, že nebylo přijato to, co mělo být odmítnuto) lol už jsem asi unavenej :D
      - $\alpha$ prostě označuje pravděpodobnost, že vznikne chyba prvního typu
      - $\beta$ označuje pravděpodobnost, že vznikne chyba 2. typu
  - p-value ... pravděpodobnost, že tak "špatná" pozorovaná data vznikla 
  - testy dobré shody
    - už se mi nechce rozepisovat...

### 4. Algoritmy a datové struktury
- asi na celý použiju knížku ["Průvodce labyrintem algoritmů"](https://pruvodce.ucw.cz/)
- fajn je pro ujasnění si pustit algoritmy tady: [Visualgo](https://visualgo.net/en)
  - a tady [Algovision](https://www.algovision.org/Algovision/pool.html)

#### 1. Časová složitost algoritmů. Metoda ,,rozděl a panuj'' - aplikace a analýza složitosti, dynamické programování.
> Časová složitost algoritmů. Metoda ,,rozděl a panuj'' - aplikace a analýza složitosti, dynamické programování.

- časová složitost algoritmů
  - kapitola 2.3 v Průvodci
  - časová složitost se obvykle uvádí v závislosti na velikosti vstupu
  - je zavedené značení složitosti podle tříd složitosti
  - každá ze tříd je definovaná podle nejrychleji rostoucího členu
    - navíc se zanedbávají konstanty
  - např. složitost $3n^2+log(n)$ je v třídě $O(n^2)$
  - formálně se to definuje takhle:
    - máme funkce $f,g: \N \rightarrow \Reals$, $c\in \Reals^{0,+}$
      - říkáme, že $f(n)$ je třídy $O(g(n))$, pokud pro "skoro všechna n" platí, že $f(n) \leq cg(n)$
    - "skoro všechna n" znamená, že může existovat konečně mnoho hodnot n, pro která nerovnost neplatí. Nebo se to může zjednodušit, že existuje nějaké $n_0$ t.ž. pro všechna $n > n_0$ je $f(n) \leq cg(n)$

- metoda rozděl a panuj
  - kapitola 10 v Průvodci
    - princip - rozdělení problému na části, které už je možné vyřešit jednoduše
  - aplikace    - příklady
      - Hanojské věže
        - přenesení celé věže až na největší kámen z 1 kolíku na 3 kolík
        - pak přesunutí hlavního kamenu z 1 kolíku na 2 kolík
        - pak přesunutí celé věže z 3 kolíku na 2 kolík
      - MergeSort
  - analýza složitosti
    - nejjednodušší je vytvořit strom rekurze
      - např. pro MergeSort
        - vytvoření stromu, kde každý uzel je slévání
          - kořen je slévání dvou polí velikosti n/2 (n je počet prvků v tříděném poli)
          - -> n/2 porovnávání
        - kořen (a každý další vrchol) má dva syny, které mají poloviční velikost, takže k-tá "hladina" vrcholů bude mít $n/2^k$ vrcholů
        - složitost bude rovna součtu operací v hladině * počet hladin
          - v k-hladině je $2^{k-1}$ uzlů a každý z nich má $n/2^k$ operací, což se v každé hladině sečte na $n/2$ operací
          - hladin je $log_2(n)$
          - složitost je $O((n/2)*log_2(n))=O(log(n))$

- dynamické programování
  - princip: převedení rekurzivního programování zpravidla do tabulky
    - využívá se toho, že podproblému v rekurzivním algoritmu mají stejná částečná řešení (kešujeme je)
    - příklady:
      - výpočet Fibonacciho čísel pomocí rekurze
      - alignment 2 sekvencí aminokyselin

#### 2. Binární vyhledávací stromy, vyvažování, haldy.
- binární vyhledávací stromy
  - kapitola 8 v Průvodci
  - v základu - zakořeněný strom, každý uzel má nejvýše 2 potomky
  - vyhledávací strom
    - levý potomek je menší než rodič a ten je zas menší než pravý potomek
    - výhoda oproti poli - rychlé vyhledávání v třídě O(log(n))
    - problém - přidávání potomků tak, aby byl strom vyvážený
      - ve špatném případě může vyhledávání trvat až O(n)
- vyvažování
  - binární vyhledávací strom je "dokonale vyvážený", pokud pro každý vrchol v platí, že $|L(v)|-|R(v)| \leq 1$
  - důležitější je pojem "hloubkově vyvážený strom" - $|h(l(v))-h(p(v))| \leq 1$
    - AVL stromy využívají hloubkové vyvážení
    - operace Insert a Delete na stromě budou normálně přidávat/odebírat vrcholy, ale pak ještě ověří, jestli strom zůstal hloubkově vyvážený, příp. udělají vyvážení
      - v každém z vrcholů je kromě hodnoty uloženo znaménko {+,0,-} - o kolik se hloubkově liší pravý a levý podstrom
      - vyvážení se dělá dvěma operacemi (Průvodce, str. 193)
        - rotace
        - dvojitá rotace
- AB-stromy
  - více hodnot ve vrcholech
  - jednodušší vyvažování
  - $a\geq 2$, $b\geq 2a-1$
  - každý uzel má a až b synů, vrchol může mít 2 až b synů
  - všechny vnější vrcholy jsou ve stejné hloubce (prázdné vrcholy),
  - pro k synů má vrchol k-1 hodnot
  - přidávání - vyhledá se místo, kam přidat hodnotu
    - pokud je v uzlu méně ne

- haldy
  - Kapitola 4.2 v Průvodci
  - halda je datová struktura ve tvaru binárního stromu
  - pro každý vrchol platí, že má nejvýše takovou hodnotu, jako jeho synové (směrem k potomkům hodnota stoupá)
  - ve vrcholu je tedy minimum
  - všechny hladiny jsou zaplněné, až na poslední
    - poslední hladina je zaplněná zleva
  - přidávání
    - prvek se přidá na co nejlevější místo v poslední hladině
    - pokud se porušilo haldové uspořádání (syn je větší než rodič), tak se "probublává" - přidaný prvek se prohodí s rodičem, vyzkouší se, jestli rodič není větší - pokud ano, zase se prohodí atd., nejvýše až ke kořenu haldy
    - přidání má složitost O(log(n)) (počet hladin)
  - odebírání
    - zpravidla se halda dělá kvůli rychlému nalezení minima
      - odebírá se minimum v kořeni
      - po odebrání kořene
        - na místo kořene jde poslední prvek v nejnižší hladině
        - probublává dolu - vyměňuje se s menším z obou synů

#### 3. Třídění
> Třídění - sekvenční třídění, porovnávací algoritmy, přihrádkové třídění, třídící sítě.


- přímé aloritmy
  - select sort
  - buble sort
  - insert sort
- rychlejší algoritmy
  - merge sort

- přihrádkové třídění,
  - counting sort
    - (započítá se, kolikrát bylo číslo k na vstupu pro čísla od 1 do r)
  - bucket sort
    - jako counting sort, jen pro obecné "klíče" u položek, místo počítadla je tam seznam
  - lexikografický bucket sort
    - pokud klíč není jedno číslo, ale k-tice čísel
    - vlastně se udělá bucket sort pro jednotlivé pozice v k-tici, začíná se s nejméně významnou
  - radix sort
    - upřímně, nechápu rozdíl mezi radix sortem a lexikografickým bucket sortem v myšlence, až na to, že lex-bucket sort třídí obecné klíče a radix sort na místo nich třídí jednotlivé číslovky, kde jedna přihrádka je dolní celá část logaritmu k o základu "z" plus 1
      - (nevím, jak se dělá dolní celá část v LaTeXu)
- třídící sítě
    - komparátorová síť
      - Průvodce, str. 392 (kapitola 15.3)
      - výstup je permutace, setříděný vstup
      - např. pro bubble sort má O(n^2) hradel na n vrstvách -> paralelizace, setřídění v O(n)
      - přes bitonické třídičky se výklad stáčí ke slévacím třídičkám
        - síťový merge sort
        - síť hloubky $\Theta(log^2n)$
          - $\Theta(nlog^2n)$ komparátorů

#### 4. Grafové algoritmy
> 4. Grafové algoritmy - prohledávání do hloubky a do šířky, souvislost, topologické třídění, nejkratší cesta, kostra grafu, toky v sítích. Tranzitivní uzávěr.

- přehled některých grafových algoritmů (abych si nepletl jména)
  - Dijkstrův algoritmus
    - hledání nejkratší cesty
    - Průvodce kap. 6.2
    - nefunguje pro záporné cykly
  - relaxační algoritmy
    - zobecnění Dikstry
    - Průvodce kap. 6.3
    - Dijkstra jen vybírá z množiny otevřených vrcholů ten s nejnižší prozatimní délkou cesty od počátku
  - BFS
    - hledání do šířky, je trochu analogický s Dijkstrovým algoritmem
    - Průvodce str. 110
  - Bellman-Fordův algoritmus
    - jako Dijkstra, jen se z otevřených vrcholů nevezme ten s nejnižším ohodnocením, ale nejdéle přidaný (fronta)
  - Floyd-Warshal
    - matice vzdáleností každého vrcholu s každým
    - Průvodce kap. 6.4
  - Ford-Fulkersonův algoritmus
    - hledání maximálního toku

- prohledávání do hloubky a do šířky
  - do šířky - BFS (breadth-first search), Průvodce str. 110 (fronta)
  - do hloubky - DFS (deep-first search), Průvodce kap. 5.6 (zásobník)
- souvislost
  - hranová vs. vrcholová souvislost
    - mosty ... hrana není most, když leží na kružnici
    - artikulace ... vrchol, jehož odebráním se graf rozpadne na více komponent
  - komponenty souvislosti (v neorientovaném grafu)
    - v náhodném nenavštíveném vrcholu spustíme BFS
      - pokud jsme navštívili všechny vrcholy -> graf je souvislý
      - jinak jsme objevili celou komponentu souvislosti
      - další komponentu nalezneme tak, že spustíme BFS na dalším dosud nenavštíveném vrcholu
  - jak rozpoznat DAG (directed acyclic graph)
    - např. spouštění DFS, podobně jako u hledání mostů, opakovaně
- topologické třídění,
  - asi ekvivalent topologického uspořádání?
  - Průvodce str. 128
  - vztahuje se na DAGy
    - nejprve se najde "zdroj"
      - ten se umaže a prohlásí za první v uspořádání
      - pak se znovu najde zdroj, druhý v uspořádání atd.
  - 
- nejkratší cesta
  - Dijkstrův algoritmus
  - Bellman-Fordův algoritmus
  - Floyd-Warshalův algoritmus

- kostra grafu,
  - graf může mít mnoho koster
  - algoritmy se mohou lišit v tom, kterou kostru naleznou
  - vždy se snaží nalézt minimální kostru (i těch ale může být i víc)
    - Jarníkův algoritmus
      - seřadí hrany podle vah
      - přidává nejmenší hranu do tvořené kostry (právě jeden z vrcholů ale musí být "nový", tj. ještě není přidaný)
      - to, že Jarníkův algoritmus dá kostru není zas tak těžké nahlédnout (vždy se přidá "nový" vrchol, takže nevznikne cyklus a každý vrchol (který není v jiné komponentě) bude nakonec přidán)
      - trochu složitější je to s minimalitou, ale to se zase nahlédne z toho, že nejlehčí hrana z nějakého elementárního řezu bude v kostře grafu
    - Borůvkův algoritmus
      - kdyby Jarník pěstoval jeden strom, Borůvka pěstuje mnoho naráz (tolik, kolik je vrcholů)
      - postupně stromy slučuje (spojuje vždy dva vrcholy nejmenší možnou hranou)
    - Kruskalův algoritmus
      - přidává do "lesa" vždy nejmenší hranu, poté, co zkontroluje, že by nevytvořila cyklus
    - Union-Find
      - datová struktura, která pomáhá u Kruskalova algoritmu
      - pro dva vrcholy zjistí, zda leží ve stejné komponentě (FIND)
      - umí přidat hranu a spojit dvě komponenty (UNION)
      - implementováno pomocí "keříků"
        - 1 komponenta = 1 keřík
        - keřík má kořen a ten má ohodnocení hloubkou
        - pokud spojíme dva keříky, přepojíme mělčí keřík pod kořen toho hlubšího

- toky v sítích
  - maximální tok = minimální řez
  - základní algoritmus je Ford-Fulkersonův
    - Ford-Fulkersonův algoritmus
      - hledá zlepšující cestu
      - vždycky se zlepší cesta o "bottle-neck"
    - FF algoritmus je dobrý i pro hledání maximálního párování v bipartitním grafu
    - Diniciův algoritmus
      - definuje si "průtok hranou"
      - síť rezerv
      - blokující tok
        - pokud je na každé cestě alespoň jedna hrana, která brání zlepšení (dosáhla kapacity)
      - pročišťování
    - Goldbergův algoritmus


- tranzitivní uzávěr
  - tranzitivní uzávěr je množina hodnot true/false pro všechny dvojice vrcholů, zda se z prvního je možné dostat do druhého nějakou cestou v grafu
  - zpravidla se reprezentuje jako matice
  - je možné jej získat pomocí Ford-Fulkersona
  - také existuje docela fajn trik
    - když se udělá matice (A), kde jednička na pozici i,j znamená, že z vrcholu i vede do vrcholu j (orientovaná) hrana, tak $A^2$ je matice, kde na pozici i-j je jednička, když vede z i do j cesta přes dvě hrany
    - pokud je v grafu n vrcholů, tak $A+A^2+...+A^n$ je matice tranzitivního uzávěru na grafu G

#### 5. Další algoritmy
> 5. Algoritmy vyhledávání v textu - Aho-Corasicková, KMP, sufixový strom, sufixové pole. Algebraické algoritmy - DFT, Euklidův algoritmus. RSA. Aproximační algoritmy. Automaty a gramatiky - typy automatů a gramatik, vztahy, příklady.

- Algoritmy vyhledávání v textu
  - Aho-Corasicková,
    - Průvodce, kap. 13.3
    - textový algoritmus pro vyhledávání mnoha slov najednou
    - FSA, zpětné hrany (failure state), zkratky
    - [Vizualizace](https://brunorb.com/aho-corasick/)

  - KMP,
    - Průvodce, kap. 13.2
    - Knuth-Morris-Pratt
    - textový algoritmus, který vyhledává výskyty pro zadané slovo
      - vytvoří se FSA s přechody mezi písmeny slova a tím se proskenuje celý text
      - oproti Aho-Corasickové dokáže vyhledat jen 1 slovo
        - FSA vypadá jako nerozvětvený řetízek
  - sufixový strom
    - je možné jej v lineárním čase převést na sufixové pole a naopak
    - Průvodce, kap. 13.5
    - trie - složená ze všech sufixů sekvence
    - vyhledáme jehlu v trii (u vrcholů je uvedené, kde mají dané sekvence začátek)
  - sufixové pole
    - asi jsme se to na ADS neučili..
    - Průvodce, kap. 13.4 (za Rabin-Carpem)
    - tabulka na opakované vyhledávání v textu
    - celý text se rozseká na všechny sufixy od pozice 1 do n (pro text délky n)
      - např. rokoko se rozseká na
        1. rokoko
        2. okoko
        3. koko
        4. oko
        5. ko
        6. o
        7. $\epsilon = \empty$
    - sufixy se setřídí abecedně a najdou se pro ně 3 hodnoty
      - X(i) ... původní pořadí v abecedě i-tého sufixu
      - R(i) ... inverzní funkce k X $\rightarrow R(X(i))=i$
      - L(i) ... nejdelší společný suffix se sekvencí, která následuje v abecedě

|$i$|$X$|$R$|$L$| sufix |
|:-:|:-:|:-:|:-:|:------|
| 0 | 6 | 6 | 0 |$\epsilon$|
| 1 | 4 | 5 | 2 | ko    |
| 2 | 2 | 2 | 0 | koko  |
| 3 | 5 | 4 | 1 | o     |
| 4 | 3 | 1 | 3 | oko   |
| 5 | 1 | 3 | 0 | okoko |
| 6 | 0 | 0 | - | rokoko|

- 
  -
    - pro zadanou "jehlu" je potřeba najít jen začátek a konec oblasti, kde sufixy začínají na tuto jehlu
    - všechny sufixy mezi nimi také začínají na jehlu, takže jejich pozice (hodnota X) vrátíme
    - protože můžeme vyhledávat binárně, časová složitost je logaritmická
    - velikost tabulky je lineární vůči délce sekvence, protože stačí uložit pouze číselné hodnoty, suffixy existují implicitně

- Algebraické algoritmy
  - DFT
    - Průvodce, kap. 17
    - Diskrétní Fourierova transformace je lineární zobrazení vektoru komplexních čísel na jiný vektor komplexních čísel podle vzorce
      - $F: \Complex^n \rightarrow \Complex^n$ tak, že
        - $F(x)=y$, $x,y \in \Complex^n$
        - $y_j = \sum_{k = 0}^{n-1} x_k × e^{-\frac{i2\pi}{n}jk}$,
          - $e^{-\frac{i2\pi}{n}}$ je jedna z primitivních n-tých odmocnin jedničky
            - také je možné ji zapsat jako
              - $cos(\frac{2\pi}{n})+isin(\frac{2\pi}{n})$
    - možná by bylo fajn trochu rozepsat FFT (Rychlou Furierovu transformaci)
    - FFT
      - implementace DFT se složitostí $\Theta(nlog(n))$
      - využívá rekurze
      - zvoli jako koeficienty pro převedení polynomu do grafového tvaru mocniny nějaké n-té primitivní odmocniny jedničky (komplexní číslo) a pak provádí rekurzivní proceduru
        - v principu - polynom rozdělí na dva, jeden se sudými a jeden s lichými koeficienty - to je možné, protože jsme zvolili hodnoty bodů, kde má být polynom vyhodnocen tak, aby body byly spárované (i-tá hodnota "x" je až na znaménko stejná, jako i+n/2 tá hodnota)
        - díky tomu, že hodnoty "x" jsou mocniny primitivního čísla, až na hodnotu "x^0" tam není jednička
        - je tam dalších několik myšlenek, díky kterým to funguje, ale v principu
        - využívá se rekurzivního převedení polynomu na jeho koordináty tak, že se v každém kroku rekurze zmenší na polovinu
      - DFT se dá využít např. pro rychlé násobení polynomu, odpovídá spektrálnímu rozkladu signálu na siny a cosiny - využívá se u MP3 a JPEG a u rozpoznávání řeči
  - Euklidův algoritmus
    - GCD (greatest common divisor)
    - Průvodce, str. 30-31
    - odčítací algoritmus
  - RSA
    - Zdroj: [Wiki](https://cs.wikipedia.org/wiki/RSA)
    - Rivest-Shamir-Adleman
    - algoritmus pro asymetrickou kryptografii, který vygeneruje veřejný a privátní klíč pro kódování/dekódování zprávy
    - jeho "neprolomitelnost" závisí na velké složitosti pro rozklad velkých čísel na prvočísla
    - vytvoření klíčů
      - náhodně se zvolí vysoká prvočísla p,q
      - n=pq
      - Eulerova funkce $\phi(n)=(p-1)(q-1)$
        - eulerova funkce dává počet čísel k od 1 do n takových, že NSD(k,n)=1
      - zvolí se celé číslo (prvočíslo) e (veřejný klíč) t.ž. $e<\phi(n)$ a $nsd(\phi(n),e)=1$ (většinou se používá e=65537)
      - najde se číslo d (privátní klíč) t.ž. $(e*d)\mod\phi(n)=1$ (to je možné v konstantním čase)
      - a to je všechno, (e,n) je veřejný klíč a (d,n) je soukromý klíč
    - zašifrování
      - m je zpráva
      - zašifrovaná zpráva $c=m^e\mod n$
    - dešifrování
      - $m = c^d \mod n$
  - Aproximační algoritmy
    - Průvodce, kap. 19.6
    - hledáme "dostatečně dobré řešení"
    - pro nějakou "cenu" řešení hledáme aproximaci, která svojí cenou nebude příliš odlišná od ceny - pro minimalizační algoritmy a $\alpha>1$, optimální cenu $c^*$ a aproximaci $c'$ bude $c'<\alpha c^*$, obdobně pro maximalizační problémy a $\alpha<1$
  
- Automaty a gramatiky
  - (1. přednáška od [Bartáka](http://ktiml.mff.cuni.cz/~bartak/automaty/lectures/lecture01.pdf))
  - typy automatů a gramatik,
    - (konečný) automat je pětice
      - množina stavů automatu
      - počáteční stav
      - přechodová funkce
      - vstupní symboly
      - množina přijímajících stavů
  - (6. přednáška od [Bartáka](http://ktiml.mff.cuni.cz/~bartak/automaty/lectures/lecture06.pdf)) gramatika je čtveřice - set neterminálních symbolů, set terminálních symbolů, počáteční terminální symbol a produkční systém
    - produkční systém vygeneruje ze zadané n-tice tvořené terminálními a neterminálními symboly jinou n-tici, první n-tice musí obsahovat alespoň jeden neterminální symbol
  - vztahy,
    - gramatika jde převést na automat
      - pravidla gramatiky se přepíšou do "hran" automatu (přechodové funkce)
      - vstupní sekvence je podle pravidel v automatu přes neterminály zpracovaná a vyústí v nějakém terminálu
  - příklady.

## 5. Aplikovaná informatika
   1. Principy a základy implementace objektově orientovaných jazyků - třída, dědičnost, polymorfismus, virtuální funkce, atd. Generické programování a knihovny šablony a generika, kompilační polymorfismus.
   2. Normální formy, referenční integrita. Základy SQL.
   3. Unix - základní pojmy (systém souborů, komunikace mezi procesy), shell (syntaxe, programové konstrukty), základní utility.
## Bioinformatika
### 1. Obor "bioinformatika"
> "Bioinformatika je souborem metod, které slouží k třídění, analýze a interpretaci biologických dat (především *in silico*)." (Janet Thornton)

- literatura
   - [Evžen - zápisky](https://eugleo.github.io/bioinformatika/doc/zaklady-bioinformatiky/notes.html)
   - [Marian - základy bioinformatiky](https://web.natur.cuni.cz/~marian/kurz/course.html)
   - [Wiki: Bioinformatics](https://en.wikipedia.org/wiki/Bioinformatics)
  
  
- definice oboru
  - bioinformatika se zabývá zpracováním biologických dat
    - sběr, 
    - archivace, 
    - organizace, 
    - interpretace
  
- historie bioinformatiky
  - 1707 - 1778 Carl Linne, první "bioinformatik"
  - 1951 Fred Sanger, sekvence proteinu insulinu
  - 1957 Perutz, Kendrew, první struktura proteinu
  - 1965 Margarett Dayhoff, první sekvenční databáze
  - 1970 Needlman - Wunsch, algoritmus sekvenčního srovnávání
  - 1971 první strukturní databáze
  - 1988 "HUGO project" ([HUman Genome Organization](https://en.wikipedia.org/wiki/Human_Genome_Organisation))
  - 1990 Altshul, Lipman et al., BLAST
  - 1992 NCBI - GenBank
  - 1995 První osekvenovaný celý genom, Haemophilus influenze

- oblasti bioinformatiky
  - sekvenční (informační biopolymery, proteiny)
  - strukturní (Struktura DNA, RNA, proteinů)
  - signální dráhy v buňkách (stará definice bioinformatiky)
  - regulace exprese genů (signalizace, epigenetika)


- biologická data
  - v základu jakákoli data (délky motýlých křídel)
  - každopádně i další data
    - genomická data
    - sekvence (proteiny, RNA, DNA)
    - interakce
    - příbuzenské vztahy etc.
  - rozsah dat?
    - EBI 2015 - 60PB dat

### 2. Sekvenční bioinformatika
- literatura
  - [Wiki CZ: Dot plot](https://cs.wikipedia.org/wiki/Dot_plot)
  - [Základy bioinformatiky na Drivu](https://drive.google.com/drive/u/2/folders/1Q6Qdnpu6WVNltm0hdHHSNKI6f4Hrsib0)
  - [Bioinformatické algoritmy na GDrivu](https://drive.google.com/drive/u/2/folders/1PxGQIhwFY3ZVHpoBSD0pbtg41LQU3QIV)

- dotplot
  - vizuální metoda pro alignment 2 sekvencí
  - postup:
    - jedna sekvence jde do řádku, druhá do sloupce
    - z teček (identita na jednotlivých pozicích) vidíme, jaké vzory se vyskytují
      - čára diagonálně zleva nahoře doprava dolů značí identický úsek
      - kolmo na tuto čáru vidíme inverzi
  - tento postup je možné použít i pro analýzu jedné sekvence
    - dáme do řádku i do sloupce tu stejnou sekvenci
      - samozřejmě bude nepřerušená čára na diagonále (identita)
      - mimo diagonálu uvidíme opakující se subsekvence a kolmo na ně inverzní opakující se subsekvence
  - nevýhoda dot-plotu je, že generuje mnoho šumu (např. pro DNA sekvenci je pravděpodobnost 1/4, že dojde k identitě na pozici u dvou náhodných sekvencí)

- substituční tabulky ([Algoritmy - 4](https://drive.google.com/drive/u/2/folders/1jAY334cmBiOS3Tx06VBPDkjNM--tGqBo))
  - při vytváření alignmentu dvou sekvencí je možné použít různé typy skórujících funkcí
    1. Hammingova vzdálenost (Hamming Distance, HD)
      - pro sekvence stejné délky!
      - identita na pozici -> 1
      - neidentita -> 0
    2. Editační (Levensteinova) vzdálenost (ED)
      - minimální Hammingova vzdálenost pro alignment dvou sekvencí
      - je možné ji spolehlivě získat pomocí dynamického programování (DP) (taková ta tabulka dvou sekvencí) a následným backtrackingem
    3. OWED (Operation-Weighted Editation Distance)
      - zobecněná ED
      - jsou zavedeny hodnoty, které mohou být upraveny pro potřeby dané situace
        - d ... penalizace za mezeru
        - e ... skóre, pokud je na pozici identita
        - r ... skóre, pokud na pozici není identita
      - je definovaná rekurzivně, ale počítá se pomocí dynamického programování
    4. AWED (Alphabet-Weighted Edit Distance)
      - OWED upravené pro specifické hodnoty d, e, r pro každou kombinaci znaků
        - znak×mezera,  
        - znak sám se sebou, 
        - znak×jiný znak
      - z AWEDu vychází většina skórujících tabulek, jen je většinou ještě nastavená jiná hodnota pro první gap a pro následující gapy (otevřít mezeru je "dražší" než ji prodloužit)
  - Skórující tabulky
    - není problém vytvořit alignment dvou sekvencí, problém je najít vhodnou skórující tabulku, aby nám nevyšla blbost
    - Probabilistic models
      - počítání skóre na základě pravděpodobnosti, že se budou dané páry znaků ve dvou sekvencích (např. aminokyselin) vyskytovat na stejné pozici
      - dva přístupy
        1. Random Model
          - jde přes všechny kombinace pozic ve dvou sekvencích
          - (jakoby for cyklus přes *i* ve for cyklu přes *j*)
          - předpokládá, že sekvence jsou unrelated
        2. Match Model
          - jde přes shodné indexy
          - (jakoby jen jeden for cyklus přes *i* pro obě sekvence naráz)
          - pravděpodobnost, že na dané pozici pochází daná rezidua ze společného předka
          - match model předpokládá, že sekvence jsou si příbuzné
      - Odds Ratio je podíl výsledku Match modelu a Random modelu
        - podíl pravděpodobnosti, že na pozici je daná kombinace znaků (např. aminokyselin) za předpokladu, že sekvence jsou příbuzné a že sekvence nejsou příbuzné
        - když vyjde vyšší než 1, daný alignment dvou pozic je pravděpodobně nějak evolučně spřízněný
        - když vyjde nižší než 1, pravděpodobně není spřízněný
      - Log Odds Ratio
        - logaritmus Odds Ratio, vyhodí použitelné hodnoty do skórovací tabulky (nespřízněné -> menší než 0, spřízněné -> vyšší než 0, ((log(1)=0)))
      - tenhle přístup má 2 problémy
        1. je potřeba dávat pozor, aby pro nějakou obecnou skórovací matici nebyly vybrány příliš příbuzné sekvence
        2. je potřeba chytře zvolit pravděpodobnost pro Match Model - u sekvencí s evolučně bližším společným předkem bude pravděpodobnost záměny na dané pozici nižší než pro sekvence se vzdálenějším (čas po který sekvence mutovaly)
    - Substituční matice PAM (Point/Percent Accepted Mutation (Dayhoff et al.)) a BLOSSUM (BLOckS SUbstitution Matrix (Henikoff et al.))
      - při tvoření matic se využívá pravděpodobnostních modelů viz výše
      - pro evoluční studie jsou běžně používány matice PAM 250 a BLOSSUM 62
      - PAM
        - vytvoří se matice PAM 1 (velmi podobné sekvence)
        - znalost o pravděpodobnostech v PAM 1 se použije pro evolučně vzdálené sekvence (PAM *n*)
        - dvě sekvence jsou 1 PAM vzdálené, pokud série mutací přeměnila jednu sekvenci na druhou pomocí 1 přijaté mutace na 100 aminokyselin (point accepted mutation)
          - přijaté (accepted) znamená, že mutace není letální a není umlčená (silent)
        - dvě sekvence vzdálené 200 PAM mají cca 25% identitu (jsou to proteinové sekvence)
        - pro *ideální* konstrukci PAM *n* matice je potřeba
          1. vzít set n PAM vzdálených sekvencí
          2. manuálně udělat jejich alignment (ještě nemáme skórovací matici, abychom to udělali automaticky)
          3. spočítat pomocí pravděpodobnostního modelu skóre v matici: $PAM_n[i,j] = log(\frac{f(i,j)}{f(i)×f(j)})$
        - *reálně* se PAM dělá pomocí markovovských modelů
          - z toho vyplývá, že PAM *n* se vyrábí umocněním PAM 1 na *n*-tou
      - BLOSSUM
        - Na bázi PROSITE
          - BLOCKS
            - bloky motivů derivované z PROSITE knihovny
        - podíl spatřených identit a očekávaných identit
        - BLOSSUM n se vytvoří tak, že z BLOCKS se odstraní sekvence s identitou vyšší než n%

- metody dynamického programování
  - optimalizace rekurzivních algoritmů
  - je potřeba zjistit, jaká část předpočítaných výsledků se shoduje
  - nějak chytře je potřeba vytvořit tabulku s těmito shodujícími se tabulkami a začít od začátku, nikoli od konce...
  - příklady: Fibonacciho číslo ... začne se od 0, 1 - > pak se pokračuje v řadě, až se dojde k n-tému číslu
  - v sekvenční bioinformatice ... Needleman-Wunsch algoritmus -> pro dvě sekvence se vytvoří tabulka s dvěma dimenzemi ...
    - definují se hodnoty na začátku, pak si algoritmus na každé pozici vybere minimum z předchozích pozic
    - backtrackingem se zjistí, jak "alignment" postupoval

- lokální a globální alignment
  - jde především o biologický pohled - zarovnání sekvencí tak, aby odpovídaly evoluční příbuznosti
  - je možné vytvořit aligment i ručně s biologickou intuicí
  - automatizace -> informatický pohled
    - jde o to najít alignment s nejlepší skórovací funkcí (AWED)
      - potřeba vhodné skórovací matice
  - globální alignment hledá alignment pro celou sekvenci
  - lokální alignment hledá alignment jednotlivých podsekvencí - předpokládá příbuznost kratších úseků, které mohou být i proházené mezi sebou
  - algoritmus pro globální alignment je možné upravit na lokální tak, že místo záporných hodnot se do tabulky pro dynamické programování vkládají nuly
    - backtracking se pak dělá pro jednotlivé podoblasti
  - algoritmus pro globální alignment (GA) se jmenuje Needleman-Wunsch
  - dtto pro lokální alignment (LA) se jmenuje Smith-Waterman

- parwise versus multiple sequence alignment
  - párový - jednoduše pomocí DP
  - u multiple sequence alignmentu stoupá složitost exponenciálně pro n sekvencí
  - skórování MSA (multiple sequence alignmentu)
    - používá se skórování přes sloupce MSA
    - dvě metody
      - ME (Minimal Entropy) - počítá pravděpodobnost, že je reziduum x na pozici i, skóre je záporně zlogaritmované, aby byla 0 nejvyšší možné skóre
      - SP - Sum of Pairs
        - v podstatě se udělá skórování pomocí PAM / BLOSSUM přes všechny dvojice v každém sloupci MSA
  - spoustu heuristických algoritmů pro MSA
    - Progressive iterative methods
      - Feng&Doolitle
      - ClustalW, Clustal Omega
    - Consistency based
      - T-Coffee
    - Iterative refinement
      - Barton&Sternberg
    - Block-Based
      - DIALIGN
    - Mix
      - MAFFT, 
      - MUSCLE


### 3. Hledání podobných sekvencí v databázích
> hledání podobných sekvencí – Blast versus FASTA - statistické zhodnocení významnosti nálezu - profilové metody (PSI-BLAST) – HMM metody

- literatura
  - [Bioinformatické algoritmy na GDrivu](https://drive.google.com/drive/u/2/folders/1PxGQIhwFY3ZVHpoBSD0pbtg41LQU3QIV), přednášky 6(, 7) a 8

- úvod
  - obří databáze - potřebujeme je efektivně prohledávat
    - v nejhorším případě lineární složitost, spíš lepší
    - optimální algoritmus má kvadratickou složitost pro sekvence
    - je potřeba využít heuristiky
  - využívá se hashování
    - list pro všechny sekvence a k-tice (všechny možné?)
      - kde v sekvenci se daná k-tice nachází
      - pomocí dvou listů, jeden (b) obsahuje pro všechny k-tice jejich první výskyt,
      - druhý (a) pro celou sekvenci dává pointry na tu další k-tici
      - lepší vysvětlení v 6. přednášce na 6. slidu

- Blast versus FASTA
  - FASTA
    - 4 kroky
      1. pro query a databázovou sekvenci se najdou všechny matchující k-tice (v tabulce podobné jako u NW algoritmu)
      2. k-tice se pospojují (za gapy mezi nimi se dává penalizace)
      3. vybere se 10 nejlepších spojených subsekvencí a oskórují se pomocí PAMu nebo BLOSSOM, z nich se započítají ty nejlépe skórující, součtem skóre subsekvencí se ohodnotí celá sekvence
      4. mezi nejlépe skórujícími sekvencemi se udělá Smith-Waterman
  - BLAST (Basic Local Alignment Search Tool)
    - algoritmus má 5 kroků, stejně jako ve FASTA jde o to najít malé množství sekvencí, které pak už budou oskórované pomocí SW algoritmu
      1. pro query sekvenci jsou zjištěny všechny její k-tice (typicky k=3)
      2. pro každou k-tici z kroku 1. jsou vygenerovány všechny teoreticky možné k-tice, které s ní budou skórovat nad určitou hodnotu (T), skóruje se pomocí PAM, či BLOSSUM
      3. pro množinu všech těchto k-tic se udělá "finite state automata (FSA)", kterým se proskenují všechny sekvence v databázi. FSA zaznamená pozici jednotlivých (hledaných) k-tic v sekvencích
      4. krok 4 má dvě varianty
         1. ve starší verzi se rozšiřují nalezené k-tice do obou směrů, dokud skóre subsekvence nespadne pod určitý limit ($X_u$), rozšířená k-tice se nazývá "high scoring pair (HSP)"
         2. v novější verzi BLASTU musí HSP obsahovat na konci rozšiřování alespoň 2 k-tice, čímž se sníží nějaká náhodnost toho procesu
      5. je stanovena hodnota $S_g$, nad kterou dosáhne skóre jen 2% HSP. Sekvence těchto vybraných HSP pak jsou normálně zalignovány pomocí SW algoritmu

  - zatímco FASTA spojuje k-tice, které jsou nalezeny v databázových sekvencích a ty se pak oskórují, BLAST pomocí všech k-tic podobných s k-ticemi v zadané sekvenci vytvoří FSA, tím najde všechna stejná místa v databázových sekvencích, tato místa pak nechá rozšířit (HSP) a ty se pak oskórují

- statistické zhodnocení významnosti nálezu
  - E-value
    - E-value rovno 1 znamená, že v prohledávané databázi se dá očekávat pro dané skóre 1 sekvence prostě náhodou
    - čím menší je E-value, tím menší je šance, že by např. vyhledaná sekvence byla vyhledána náhodně.
    - ve velkých databázích by krátké sekvence měly vysoké E-value, i kdyby byly třeba velmi podobné vstupní sekvenci
    - E-value je definovaná pomocí Gumbelova (extrémového) rozdělení
      - E-value je pravděpodobnost, že dobrý alignment nějaké sekvence v databázi má vyšší skóre, než skóre daného hitu
        - Gambelovo rozdělení má CDF definovanou jako $exp(-e^{-\lambda (x-\mu)})$, $\lambda$ je rozptyl a $\mu$ střední hodnota
        - E-value je pak 1-$exp(-e^{-\lambda (x-\mu)})$
        - tohle E-value je trochu jiné, než databázové E-value
          - FASTA to vypočítané E-value pronásobí počtem sekvencí v databázi
          - BLAST počítá s tím, že delší sekvence mají větší šanci na to být hitnuté
            - pronásobí E-value $×\frac{N}{n}$, kde N je počet reziduí v sekvenci a n je délka nalezené sekvence

- profilové metody (PSI-BLAST) (lecture-09, první polovina)
  - hledají se konzervovaná místa (např. Prosite databáze)
  - přístupy mají různou komplexitu, dávají různé množství informací
  - konsenzus sekvence ("úplně jednoduchý grep"), jen aminokiselina a jeden wild-card - *
  - patterns - grep patterny,
    - má trochu upravenou syntax
      - wildcard ... X
      - [] místo ^ etc.
  - PSSM (Position specific scoring matrix)
    - Hoksza o PSSM říká, že na nich většina studentů u státnic zbytečně pohoří!!! :// Creepy
    - také se nazývá profil
    - pro daný MSA se spočítají frekvence jednotlivých typů aminokyselin na určitých pozicích
    - video [přednášky Hokszy](https://drive.google.com/file/d/1XTO0RUbab7IxBHANDX8nKfClvE1H7FZo/view?usp=sharing) od Matěje Zátka je pure gold, na 20:00 kočka Hokszovi ničí mikrofon u sluchátek :D
    - PSSM hodnoty pro jednotlivé aminokyseliny se ještě upraví pomocí pseudo-countů, aby se trochu oslabil vliv toho, co vidíme a měly šanci i jiné aminokyseliny - dává se to kvůli tomu, aby se oslabil vliv toho, že jsem neviděl všechny sekvence z celé té rodiny, v některé sekvenci by třeba nějaká jiná aminokyselina byla.
      - tato hodnota se v PSSM pro danou aminokyselinu na dané pozici se tedy spočítá takto:
        - *n* ... počet reálných výskytů aminokyseliny v alignmentu
        - *k* ... počet sekvencí v alignmentu
        - *a* ... počet aminokyselin (jo jde to určitě i pro nukleotidy?)
        - *ps* ... pseudocount
        - $f_{ij} = \frac{n+ps}{k+a*ps}$
    - pak se to celé ještě prožene log-likelihood ratio nulového modelu
      - $s_{ij}=log(\frac{f_{ij}}{q_i})$
        - kde $f_{ij}$ je ta pseudocountovaná hodnota
        - $q_i$ je pravděpodobnost, že na i-té pozici by daná aminokyselina byla náhodně
    - hodnoty tabulky pak říkají, kolikrát je pravděpodobnější, že hodnota v sekvenci pochází z match modelu než random modelu (pokud je vyšší než 0), nebo kolikrát je pravděpodobnější random model než match model (pokud je nižší než 0) 
    - s PSSM se pak jede přes všechny pozice ve zkoumané sekvenci a pro každou pozici se zapisuje skóre
    - nevýhoda, neumožňuje inzerce a delece
    - nechce se mi teď zpětně přepisovat ještě poznámky, ale rád bych líp shrnul postup pro PSSM
      1. vytvoření dobrého MSA sekvencí s motivem
      2. vytvoření PSSM
         1. zaznamenání počtu výskytů jednotlivých reziduí na daných pozicích
         2. volba hodnoty pseudo-countu
         3. spočtení $f_{ij}$ - pseudocountované pravděpodobnosti výskytu reziduí na daných pozicích
         4. log-likelihood ratio (převedení pravděpodobnosti na skóre, využívá se znalosti random a match modelu)
      3. použití PSSM na dané sekvenci
         1. oskórování všech pozic pomocí PSSM
  - PSI-BLAST (Position Specific Iterated Basic Local Alignment Search Tool)
    - je to docela super v tom, že se naleznou vzdálenější homologové než jen pomocí BLASTu, ale může to občas vyhledat něco dost mimo - přidá to do PSSM nějakou nesouvisející sekvenci (profile drift)
    - využívá to metod BLASTu (P) a PSSM
    1. pro zadanou sekvenci se vyhledají pomocí BLASTP podobné sekvence
    2. z nejlepších vyhledaných se udělá MSA
    3. z MSA se vytvoří PSSM
    4. profil (PSSM) se použije pro další vyhledávání v databázi pomocí BLASTP
    5. pokud jsou nové hity, přidat do MSA a vytvořit nový profil
    6. opakovat 4. a 5., dokud jsou nalézány nové hity

- HMM metody (v přednáškách 07, 08, 09)
- HMM metody (lecture-09, druhá část, cca slide 25)
  - PSSM má nevýhodu, že neumí inzerce a delece
  - např. Viterbi algoritmus
    - zjišťuje nejpravděpodobnější variantu (nikoli nejpravdivější), jak by mohla být jakoby zalignovaná zkoumaná sekvence za předpokladu, že patří do příbuzné skupiny k určitému motivu
  - sestrojení FSA, kde jsou tři typy průchodů pro každou pozici
    - *match*
    - *insert*
    - *delete*
  - jde o to najít pravděpodobnosti přechodů
  - ty se vypočítají podobně jako u PSSM z poměrů toho, jak jdou jednotlivé "matche", "inzerce" a "delece" v MSA a plus se to ještě pseudo-countuje
<!-- TODO ... -->


### 4. Domény a motivy
> hledání domén a motivů – predikce transmembránových proteinů – predikce buněčné lokalizace a postranslačních modifikací

- literatura
  - [Bioinformatické algoritmy na GDrivu](https://drive.google.com/drive/u/2/folders/1PxGQIhwFY3ZVHpoBSD0pbtg41LQU3QIV)

- hledání domén a motivů
  - to je docela dost pokryté ve 3. otázce
  - možná by bylo fajn tu sepsat databáze, které se toho týkají
    - Prosite
      - [webovky](http://www.expasy.ch/prosite) (od SwissProtu)
      - motivy, proteinové domény, rodiny a funkční místa
      - dobře se v tom vyhledává - generalized profiles, Pftools
    - CDD
      - [webovky](https://www.ncbi.nlm.nih.gov/cdd/)
      - Conserved Domains Database
      - obsahuje předvytvořené MSA (PSSM)
      - poskytuje variantu PSI-BLAST
    - Pfam
      - [webovky](http://pfam.xfam.org/)
      - kolekce domén a families,
      - pro vyhledávání jsou použity HMM
      - V SOUČASNOSTI JE PROVOZ UKONČEN A PŘEVEDEN NA INTERPRO
    - InterPro
      - [webovky](https://www.ebi.ac.uk/interpro/)
      - sdružuje členské databáze, které je možné prohledávat z jejich interfacu...

- predikce transmembránových proteinů
  - TODO Nemůžu najít přednášku?


- predikce buněčné lokalizace a postranslačních modifikací
  - TODO Materiály

### 5. Databáze
> databáze – vlastnosti databází – formáty dat- validace dat – významné bioinformatické databáze

- literatura
  - [Bioinformatické algoritmy na GDrivu](https://drive.google.com/drive/u/2/folders/1PxGQIhwFY3ZVHpoBSD0pbtg41LQU3QIV), přednáška 2

- vlastnosti databází
  - trochu nechápu otázku, jakože vyjmenovat obecně vlastnosti bioinformatických databází?

- formáty dat (skoro všechny mají wiki stránku)
  - FASTA
    - prostě jen název sekvence a sekvence (DNA i proteiny)
  - Formáty dat ze sekvenačních experimentů
    - GenBank Flat File Format ([sample](https://www.ncbi.nlm.nih.gov/Sitemap/samplerecord.html))
    - FASTQ
      - podobné jako FASTA, obsahuje ještě data o kvalitě sekvenování
    - SAM
      - obsahuje data ze sekvenátoru, ještě více informace, než FASTQ
    - BAM
      - binární verze SAM filu

  - VCF
    - variant calling format
      - obsahuje varianty v genomických datech

  - [BED](https://en.wikipedia.org/wiki/BED_(file_format))
    - Browser Extensible Data
    - obsahuje informace o genomických regionech...

  - soubory v PDB databázi
    - PDB file
      - human readable
      - pozice jednotlivých atomů
      - proteinová sekvence
      - zastaralý
    - mmCIF
      - macro-molecule crystalographic information file
      - modernější PDB soubor, hůře čitelný, ale obecně lepší pro software a má neomezenou kapacitu (PDB format se vyvinul asi z děrných štítků)

- validace dat
  - TODO Trochu netuším, co sem dát :D Asi jsme se to neučili nebo nevím, nevím jakým směrem by to mělo jít.

- významné bioinformatické databáze
  - RefSeq, GeneBank
    - obojí pro genomická data
    - RefSeq je "curated", vybírá existující data a pak je teprve přidává, také má jen modelové organizmy

  - PDB
    - struktury proteinů
    - anotace etc.
    - konsorcium
      - rcsb-PDB, PDBe, PDBJ
      - v každé z poboček jsou stejná data
      - interface si řeší každá pobočka sama
    - web interface, FTP, API
    - každý protein má čtyřznakový permanentní kód (číslo a tři písmena)
    - formáty - PDB a mmCIF
      - ukládají se nejen proteiny, ale i ligandy a DNA
  - [SCOP](https://scop.mrc-lmb.cam.ac.uk/) - Structural Classification of Protein Structures
    - human curated
    - hierarchická klasifikace proteinů
      - podle funkční a strukturní blízkosti
  - [CATH](http://www.cathdb.info/)
    - podobně jako CATH, ale automatizovaná
  - UniProt
    - zahrnuje i SwissProt
    - UniProtKB
      - SwissProt
        - reviewed
      - TrEMBL
        - unreviewed
    - UniRef
      - 3 databases of clustered proteins
    - UniParc
      - sbírá data z veřejných databází a třídí je tak, aby nebyly redundantní
  - PIR
  - PROSITE, Pfam (InterPro), Silva

### 6. Alignment struktur
> strukturní srovnávání – hledání podobných struktur

- Literatura
  - [Bioinformatické algoritmy na GDrivu](https://drive.google.com/drive/u/2/folders/1PxGQIhwFY3ZVHpoBSD0pbtg41LQU3QIV), přednášky na (11) "Protein structure similarity"

- strukturní srovnávání
  - strukturní podobnost - podobný fold etc.
    - global similarity
    - local similarity
      - globálně odlišné proteiny mohou sdílet stejnou funkci -> stejná vazebná/aktivní místa
  - algoritmy pro hledání proteinových struktur
    - zpravidla pracují s párem proteinových struktur, které jsou reprezentovány souřadnicemi atomů (např. mmCIF formát)
    - vyhodí nějaké číslo
  - RMSD
    - Root Mean Square Deviation
    - pro dvě dané struktury (stejný počet atomů)
      - $RMSD(S_1, S_2) = \sqrt{\frac{1}{N}\sum_{i=1}^{N}\sigma_{i}^2}$
        - $\sigma_i$ je euklidovská vzdálenost mezi i-tými atomy
    - aby RMSD mělo nějakou hodnotu, je potřeba struktury nejprve zarovnat (i identické, ale posunuté struktury budou mít nenulové RMSD)
    - superposition-based similarity
      - hledá ideální superpozici dvou struktur
      - obecně má 4 kroky
        1. pro dvě zaddané struktury (P1, P2) jsou extrahovány jejich vlastnosti (pro struktury jsou vygenerované množiny vektorů jejich vlastostí)
        2. na množinách vlastností je vytvořen alignment (podobnost dvojic)
        3. vytvoření strukturní superpozice
        4. skórování alignmentu
      - spoustu přístupů
        - jen v PDB je jich hned několik
          - DALI
          - CE
          - MAMMOTH
        - dále např. FATCAT, PROSUP, STRUCTAL
    - DALI
      - distance matrix alignment
        - 2D reprezentace 3D struktur
          - vytvoření 2D matice, nezávislá na coordinátech
          - zajímá nás matice intrareziduálních vzdáleností
          - čím blíže jsou rezidua blíže u sebe, tím je v matici vyšší skóre
          - relativně jednoduché odhalování helixů etc.
          - ve 2D maticích jsou postupně nalézané stejné patterny
          - vytvoří se alignment na začátku
          - alignment se seeduje (přidávají se postupně dvojice aminokyselin), monte carlo metoda, využívá se rozdíl ve skóre alignmentu
          - skóre - rigidní a elastická podobnost
      - CE
        - postupně hledá podobné strukturní (AFP, aligned fragment pair) úseky jdoucí v sekvencích po sobě
        - kombinatoricky vyhledává optimální AFP s ohledem na minimalizaci RMSD
      - PROSUP, STRUCTAL
        - opakovaný alignment struktur
          1. vytvoří se první seed - alignment
          2. na základě tohoto alignmentu se zarovnají struktury (nová superpozice)
          3. v rámci této superpozice se vytvoří matice vzdáleností
          4. tato matice je použita pro vytvoření nového alignmentu pomocí dynamického programování
          5. vznikne nový alignment, takže se jde na krok 2 - opakuje se až do konvergence

      - SSAP
        - založené na 2 úrovních dynamického programování
          - pro každou kombinaci aminokyselin se struktury zalignují a vznikne tedy n tabulek dynamického programování se vzdálenostmi aminokyselin
          - ve druhém kroku se tabulky sečtou a ze skóre se určí optimální alignment


- hledání podobných struktur
  - <!-- TODO? Nenašel jsem v prezentacích! -->

### 7. Predikce struktury makromolekul
> predikce struktury makromolekul

- literatura
  - [Bioinformatické algoritmy na GDrivu](https://drive.google.com/drive/u/2/folders/1PxGQIhwFY3ZVHpoBSD0pbtg41LQU3QIV), přednáška 12

- v motivaci stojí především to, že znalost struktury makromolekul nám pomůže objasnit jejich funkci (platí dvojnásob u preteinů)
  - a dá nám to i spoustu dalších informací, jako jak mohou být funkce regulovány, chování v roztoku etc.
- struktura makromolekul může být zpravidla experimentálně určena, ale pro např. drug design by bylo mnohem praktičtější umět vlastnosti biopolymerů simulovat na počítači
- pro určení struktury makromolekul se používá
  1. **rentgenová** krystalografie (difrakce X-ray paprsků)
  2. NMR spektroskopie (**nuclear magnetic resonance**, dá hodnoty vzdáleností různých typů atomů od sebe, zpětně se konstuuje struktura)
  3. **3D cryo elektronová mikroskopie** (mnoho 2D snímků naráz po megarychlém zchlazení -> 3D mapa hustoty částic -> konstruování modelu z mapy)
- pro odhad struktury se používají 2 typy metod
  - **de novo**
  - **homologní** modelování
- je fajn do začátku zmínit, že pro proteiny do určité míry platí tzv. **Anfinsenovo paradigma**, které říká, že struktura proteinu závisí pouze na primární struktuře (čili že nám naše snažení o odhad struktury reálného proteinu nekazí např. nějaké zlovolné posttranslační modifikace)
- de novo metody
  - mají několik podkategorií
    - tak trochu fyzikální metody, které napodobují folding proteinů třeba v buňce
      - nejhojněji je dneska používána metoda **molekulové dynamiky**, která pro každý krátký časový krok v simulačním čase konstruuje pro každou částici silová pole, která na ní působí a na jejich základě pak pohne s částicí
      - u de novo metod je možná fajn říct, jaké používají různé potenciály
        - mezi každými dvěma částicemi je nevazebný potenciál
        - další potenciál je pro délky vazeb (vazebný potenciál)
        - pak je úhlový potenciál pro tři po sobě jsoucí částice
        - nakonec dihedrální potenciál, který se týká úhlu, který svírají 4 po sobě jdoucí částice v řetězci
        - daly by se najít i další potenciály, které se týkají dalších specifických věcí, např. potenciál pro S-S můstky, elektrostatický potenciál atd.
  - conformation space exploring (prozkoumání možností, jaké má protein na sbalení)
    - za zmínku stojí i Monte Carlo metody, které nějakým způsobem (zpravidla trochu náhodně) hýbají řetězcem proteinu a na základě energie (potenciální energie <=> potenciálu) v systému pak přijímají nebo zahazují nové stavy. to se opakuje zpravidla do ustálení systému
      - je to docela vhodná strategie pro prozkoumávání celého prostoru všech konformací proteinů - všechny prozkoumat nejdou (viz **Levinthalův paradox**)
  - **fragment-based** approaches
    - jednotlivé podsekvence mohou být docela dobře definované (motivy)
    - toho je možné využít a už je jen vhodně poskládat, aby vytvořili správnou strukturu
- **template-based** metody
  - obecně se dá postup těchto metod shrnout do 7 kroků
    1. pro zadanou sekvenci aminokyselin najít podobné se známou strukturou -> vytvoření templatu
    2. alignment zadané sekvence s nalezenou sekvencí
    3. pro konzervované regiony (aktivní místa etc.) rovnou použít pozice atomů u známé struktury pro zadaný protein
    4. vytvořit model pro ostatní regiony
    5. modelovat v těchto regionech postranní řetězce aminokyselin
    6. optimalizovat model
    7. vyzkoušet kvalitu získaného modelu
  - pro výběr tempatu se dá použít BLAST, FASTA nebo PSI-BLAST
  - alignment je dobré udělat s více sekvencemi najednou - lepší odhalení reálně konzervovaných regionů
  - dobře konzervované úseky pro překopírování jsou zpravidla nějaké sekundární struktury
  - velmi obtížné modelování loopů - zpravidla nejsou dobře konzervované, změna jedné aminokyseliny v tomto úseku většinou neovlivní funkci proteinu
  - optimalizace 
    - zkoušení rotace jednotlivých postranních řetězců a drobné změny v $C_\alpha$ backbonu struktury
    - dále zpravidla něco na způsob molekulové dynamiky
      - silová pole dokončí nuance ve vzájemných polohách atomů
  - threading a profile-based metody - když chybí blízký homolog, ale existují alespoň podobné struktury (podrobně popsané v přednášce 12, slidy 49-53)
  - **vyhodnocení se dělá zpravidla pomocí RMSD a GDT-TS**
    - RMSD je fajn, ale kvadratické -> hodně ošklivé RMSD i pro velmi hezky namodelované struktury
    - RMSD je kvadratické - i jedna velmi vzdálená subsekvence RMSD silně zvýší
    - **GDT-TS**
      - nevím jak vysvětlit, je to na slidu 57, 12 přednáška
  - je spoustu nástrojů, které tento přístup používají
    - MODELLER, ROSSETA, **SWISS-MODEL** etc.
    - budu se spíš věnovat **AlphaFoldu 2**, který je v současnosti zdaleka nejlepší (vyhrál CASP 14 (2020) s ohromným předstihem)
      - ... v přednášce

### 8. Fylogenetika
> fylogenetika – stavba stromů – základní metody tvorby stromů (ML, MP, NJ, Bayes) – bootstrap analýza

- literatura
  - [Bioinformatické algoritmy na GDrivu](https://drive.google.com/drive/u/2/folders/1PxGQIhwFY3ZVHpoBSD0pbtg41LQU3QIV), přednáška 10, v podstatě ta přednáška pokrývá celou otázku

- fylogenetika
  - věda o evoluční spřízněnosti
  - je možné dělat fylogenetiku např. na základě fosilií a porovnávání znaků organizmů
  - bioinformatika vidí genové sekvence jako molekulární "fosilie"
    - rozdíl mezi sekvencemi je výsledkem v čase se hromadících mutací, což zpětně dělá rozdíl i ve fenotypu organizmů
  - předpoklady pro zkoumání fylogenetiky na sekvencích
    - zkoumané sekvence jsou homologní (předpokládá se společný předek)
    - jednotlivé pozice v sekvencích se vyvíjely nezávisle na sobě navzájem

- stavba stromů
  - nejdřív něco o stromech
    - stromy jsou grafy, každý uzel grafu znamená jednu zkoumanou sekvenci
    - mohou být zakořeněné -> pak dávají sekvence hierarchii
    - pokud nejsou zakořeněné, tak jsou si všechny sekvence jakoby rovné
    - hrany stromu mohou a nemusí být ohodnoceny funkcí vzdálenosti sekvencí
    - pojmy
      - taxa
        - jeden druh
      - clade - monofyletická skupina
        - skupina s jedním společným předkem
      - lineage
        - větev, která ukazuje vztah ancestor-descendant
      - fylogeneze
        - topologie fylogenetického stromu
  - jak rekonstruovat strom?
    - unresolved tree
      - všechny listy jsou připojeny ke společnému předku
    - multifurcation -> strom, kde jeden taxon má více než dva potomky (chceme získat bifurkace)
    - vytvoření stromu má dvě fáze
      1. vytvoření nezakořeněného stromu (topologie) (pro N uzlů jich je (2N-5))
      2. zakořenění stromu
        - dvě možnosti
          - middleway
            - vezmu dvě nejvzdálenější taxy a přesně mezi ně ve stromě dám kořen
            - předpokládá, že jsou evoluční hodiny (rychlost mutací) konstantní, což často neplatí
          - outgroup
            - přidám taxu vzdáleně příbuznou se zkoumanými sekvencemi (má s ostatníma společného předka, ale mimo zkoumanou skupinu a se všemi steného)
  - stromy 
  - Cladogram ... délky hran nemají žádný význam
  - Phylogram ... délky hran označují evoluční odlišnost mezi uzly
  - Newick format ... jsou reprezentovány v textové podobě, jako uzávorkované skupiny
- postup 
  1. výběr sekvencí
  2. MSA sekvencí
  3. výběr modelu evoluce - získání evolučních vzdáleností
  4. vybudování stromu
  5. vyhodnocení
- výběr sekvencí
  - podle rychlosti evoluce
    - nejpomalejší ribozomální RNA
    - kódující DNA
    - nekódující DNA
    - mitochondriální DNA
- měření rychlosti mutace
  - p-distance
    - $p = \frac{D}{L}$
      - počet změněných mutací děleno délkou sekvence
      - nevýhody: často dojde ke změně na jedné pozici vícekrát
      - u krátkých sekvencí udělá i jen pár změn velký rozdíl v p-distance
  - poisson-corrected distance
    - zkombinujeme pozorovaný počet mutací (p-distance) a aktuální počet mutací
      - předpoklad, že pravděpodobnost výskytu k událostí se řídí poissonovým rozdělením
      - v přednášce je vysvětlen postup, jak se k tomu dostat
        - vzoreček je $d_p=-ln(1-p)$ 
  - Jukes-Cantorův model

- základní metody tvorby stromů (ML, MP, NJ, Bayes)
  - distance-based metody
    - UPGMA a Neighbor join (NJ)
  - character based
    - maximum parsimony (MP)
    - maximum likelihood (ML)
  - UPGMA
    - Unweighted Pair Group Method with Arithmetic Mean
    - předpoklad konstantních molekulárních hodin
    - jednoduchá metoda
    - spočítá se vzdálenost všech sekvencí mezi sebou
    - ti nejbližší jsou prohlášeni za sousedy
    - update vzdáleností
      - pokud bych spojil sekvence A a B, pak sekvence C bude mít k A-B vzdálenost vzdálenosti $(A-C + B-C)/2$
    - UPGMA funguje úplně správně, jen když je strom ultrametrický
  - Neighbor Join
    - pokud jsou vzdálenosti mezi listy *aditivní*
    - postup
      - máme multifurkaci
      - postupně vybíráme, které taxony propojíme novým uzlem
      - vytvoříme vzdálenostní matici mezi uzly
      - matici modifikujeme (vznikne nová matice "D") ... úplně jsem nepochopil proč, ale má se od vzdáleností odečíst ještě průměr vzdáleností k ostatním uzlům
      - z uzlů i, j definujeme nový uzel "k" se vzdálenostmi k ostatním uzlům m
        - $d_{km}=1/2(d_{im}+d_{jm}-d_{ij})$
      - takhle postupujeme až dokud nemáme nezakořeněný strom
      - strom zakořeníme (ideálně neighbor-join)
  - parsimonie
    - snaha vysvětlit evoluci sekvencí
    - včetně snahy o nalezení pravděpodobného předka
    - tradiční parsimonie
      - 1 substituce má hodnotu 1
    - modifikovaná parsimonie
      - různé záměny mají různou hodnotu
  - [TODO: Maximum Likelihood není pokrytý v přednášce](http://www.deduveinstitute.be/~opperd/private/max_likeli.html)

- bootstrap analýza
  - jde o to zjistit, jestli jsou fylogenetické stromy vygenerovány správně
  - generování podobných sekvencí, jako byl vstupní dataset
    - např. vynechání malé části, či prohozené sloupce
    - může se udělat třeba 1000 replik a pro každou z nich se udělá strom
    - udělá se konsenzus strom - z těch 1000 replik
    - změří se, kolikrát můj původní strom byl obsažen v tom konsenzus stromě
- 

